{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import math, random\n",
    "import nltk\n",
    "\n",
    "#Get our data\n",
    "#Label data based on rating\n",
    "#Extract features\n",
    "#split between train, dev, and test\n",
    "\n",
    "#Choose classifier \n",
    "#Train classifier (on train data)\n",
    "\n",
    "#Test classifier (on dev data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get our data\n",
    "\n",
    "#standard preprocessing\n",
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "EOJ = 'xeoj'  # end of joke tag\n",
    "\n",
    "#get jokes:\n",
    "PATH=Path('data')\n",
    "\n",
    "files = list(PATH.iterdir())\n",
    "\n",
    "for fname in files:\n",
    "    if \"eddit\" in str(fname):\n",
    "        reddit_dataset = str(fname)\n",
    "    if \"upid\" in str(fname):\n",
    "        stupid_dataset = str(fname)\n",
    "reddit_jokes = json.load(open(reddit_dataset))\n",
    "stupid_jokes = json.load(open(stupid_dataset))\n",
    "\n",
    "#discard reddit jokes with 0 score:\n",
    "rated_jokes = [joke for joke in reddit_jokes if joke['score'] > 0]\n",
    "\n",
    "#regularize to match stupid_jokes:\n",
    "title_body = [joke['title']+' '+joke['body'] for joke in rated_jokes]\n",
    "\n",
    "all_jokes = []\n",
    "for i in range(len(reddit_jokes)):\n",
    "    r_joke = reddit_jokes[i]\n",
    "    #|print(r_joke)\n",
    "    r_joke['rating']=round(math.log(r_joke['score']+random.randrange(1,10))/math.log(10)*5/2, 2)\n",
    "    if r_joke['rating']>5:\n",
    "        r_joke['rating']=5\n",
    "    del r_joke['score'] \n",
    "    r_joke['body'] = r_joke['title']+\" \"+r_joke['body']\n",
    "    del r_joke['title']\n",
    "for s_joke in stupid_jokes:\n",
    "    del s_joke['category']\n",
    "\n",
    "#combine joke sets:\n",
    "combined_jokes = reddit_jokes + stupid_jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91745, 106581)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Group into funny and notFunny sets:\n",
    "\n",
    "funny_joke_list = []\n",
    "not_funny_joke_list = []\n",
    "for joke in combined_jokes:\n",
    "    if joke[\"rating\"] >= 2.5:\n",
    "        funny_joke_list.append(joke)\n",
    "    else:\n",
    "        not_funny_joke_list.append(joke)\n",
    "        \n",
    "(len(funny_joke_list), len(not_funny_joke_list) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get unigrams and bigrams:\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "def normalize(text):\n",
    "    tokenized_text = []\n",
    "    tags = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        intermediate = [word for word in nltk.word_tokenize(sent) if (word not in stopwords) and ]\n",
    "        for word, pos in nltk.pos_tag(intermediate):\n",
    "            tokenized_text.append(word.lower())\n",
    "            tags.append(pos)\n",
    "    return tokenized_text, tags\n",
    "\n",
    "def get_ngrams(tokens):\n",
    "    unigrams = nltk.FreqDist(tokens)\n",
    "    bigrams = nltk.FreqDist(nltk.bigrams(tokens))\n",
    "    \n",
    "    feature_vector = {}\n",
    "    for token, freq in unigrams.items():\n",
    "        feature_vector[\"UNI_%s\" %(token)] = float(freq)/unigrams.N()\n",
    "    for (token1, token2), freq in bigrams.items():\n",
    "        feature_vector[\"BI_(%s,%s)\" %(token1,token2)] = float(freq)/bigrams.N()        \n",
    "    return feature_vector\n",
    "        #\"%s ahhhhh! %s\" %(\"sdflks\", \"sdff\")\n",
    "    \n",
    "def get_pos(tags):\n",
    "    unigrams = nltk.FreqDist(tags)\n",
    "    bigrams = nltk.FreqDist(nltk.bigrams(tags))\n",
    "    \n",
    "    feature_vector = {}\n",
    "    for token, freq in unigrams.items():\n",
    "        feature_vector[\"UNIPOS_%s\" %(token)] = float(freq)/unigrams.N()\n",
    "    for (token1, token2), freq in bigrams.items():\n",
    "        feature_vector[\"BIPOS_(%s,%s)\" %(token1,token2)] = float(freq)/bigrams.N()        \n",
    "    return feature_vector\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "funny_feature_tuples = []\n",
    "for joke in funny_joke_list[:2000]:\n",
    "    tokens, tags = normalize(joke[\"body\"])\n",
    "    funny_feature_tuples.append(({**get_ngrams(tokens), **get_pos(tags)},\"funny\"))\n",
    "    \n",
    "unfunny_feature_tuples = []\n",
    "for joke in not_funny_joke_list[:2000]:\n",
    "    tokens, tags = normalize(joke[\"body\"])\n",
    "    unfunny_feature_tuples.append(({**get_ngrams(tokens), **get_pos(tags)},\"unfunny\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'BIPOS_(,,IN)': 0.014388489208633094,\n",
       "  'BIPOS_(,,JJ)': 0.007194244604316547,\n",
       "  'BIPOS_(,,NN)': 0.007194244604316547,\n",
       "  'BIPOS_(,,NNP)': 0.014388489208633094,\n",
       "  'BIPOS_(,,NNS)': 0.007194244604316547,\n",
       "  'BIPOS_(,,PRP$)': 0.007194244604316547,\n",
       "  'BIPOS_(,,VBP)': 0.007194244604316547,\n",
       "  'BIPOS_(,,VBZ)': 0.014388489208633094,\n",
       "  'BIPOS_(.,JJ)': 0.007194244604316547,\n",
       "  'BIPOS_(.,POS)': 0.007194244604316547,\n",
       "  'BIPOS_(.,RB)': 0.007194244604316547,\n",
       "  'BIPOS_(.,VBZ)': 0.007194244604316547,\n",
       "  'BIPOS_(CC,NNS)': 0.007194244604316547,\n",
       "  'BIPOS_(CC,VBZ)': 0.02877697841726619,\n",
       "  'BIPOS_(DT,.)': 0.007194244604316547,\n",
       "  'BIPOS_(DT,JJ)': 0.007194244604316547,\n",
       "  'BIPOS_(DT,NN)': 0.02877697841726619,\n",
       "  'BIPOS_(DT,NNP)': 0.007194244604316547,\n",
       "  'BIPOS_(IN,DT)': 0.014388489208633094,\n",
       "  'BIPOS_(IN,NNP)': 0.02158273381294964,\n",
       "  'BIPOS_(IN,PRP$)': 0.02158273381294964,\n",
       "  'BIPOS_(IN,PRP)': 0.014388489208633094,\n",
       "  'BIPOS_(IN,RB)': 0.007194244604316547,\n",
       "  'BIPOS_(JJ,DT)': 0.007194244604316547,\n",
       "  'BIPOS_(JJ,IN)': 0.007194244604316547,\n",
       "  'BIPOS_(JJ,JJ)': 0.007194244604316547,\n",
       "  'BIPOS_(JJ,NNP)': 0.007194244604316547,\n",
       "  'BIPOS_(JJ,VBZ)': 0.007194244604316547,\n",
       "  'BIPOS_(MD,VB)': 0.007194244604316547,\n",
       "  'BIPOS_(NN,,)': 0.014388489208633094,\n",
       "  'BIPOS_(NN,.)': 0.014388489208633094,\n",
       "  'BIPOS_(NN,CC)': 0.02877697841726619,\n",
       "  'BIPOS_(NN,IN)': 0.02877697841726619,\n",
       "  'BIPOS_(NN,NN)': 0.014388489208633094,\n",
       "  'BIPOS_(NN,NNP)': 0.007194244604316547,\n",
       "  'BIPOS_(NN,PRP)': 0.007194244604316547,\n",
       "  'BIPOS_(NN,RB)': 0.007194244604316547,\n",
       "  'BIPOS_(NN,VBZ)': 0.014388489208633094,\n",
       "  'BIPOS_(NNP,,)': 0.02158273381294964,\n",
       "  'BIPOS_(NNP,NN)': 0.014388489208633094,\n",
       "  'BIPOS_(NNP,NNP)': 0.06474820143884892,\n",
       "  'BIPOS_(NNP,NNS)': 0.007194244604316547,\n",
       "  'BIPOS_(NNP,VBP)': 0.007194244604316547,\n",
       "  'BIPOS_(NNP,VBZ)': 0.03597122302158273,\n",
       "  'BIPOS_(NNP,WRB)': 0.007194244604316547,\n",
       "  'BIPOS_(NNS,,)': 0.007194244604316547,\n",
       "  'BIPOS_(NNS,IN)': 0.007194244604316547,\n",
       "  'BIPOS_(NNS,MD)': 0.007194244604316547,\n",
       "  'BIPOS_(NNS,VBP)': 0.007194244604316547,\n",
       "  'BIPOS_(POS,NN)': 0.007194244604316547,\n",
       "  'BIPOS_(PRP$,NN)': 0.04316546762589928,\n",
       "  'BIPOS_(PRP$,NNP)': 0.007194244604316547,\n",
       "  'BIPOS_(PRP$,NNS)': 0.007194244604316547,\n",
       "  'BIPOS_(PRP,RB)': 0.007194244604316547,\n",
       "  'BIPOS_(PRP,VBZ)': 0.04316546762589928,\n",
       "  'BIPOS_(RB,.)': 0.007194244604316547,\n",
       "  'BIPOS_(RB,CC)': 0.007194244604316547,\n",
       "  'BIPOS_(RB,IN)': 0.007194244604316547,\n",
       "  'BIPOS_(RB,NNP)': 0.007194244604316547,\n",
       "  'BIPOS_(RP,,)': 0.014388489208633094,\n",
       "  'BIPOS_(VB,DT)': 0.007194244604316547,\n",
       "  'BIPOS_(VBN,IN)': 0.014388489208633094,\n",
       "  'BIPOS_(VBP,DT)': 0.007194244604316547,\n",
       "  'BIPOS_(VBP,NNP)': 0.007194244604316547,\n",
       "  'BIPOS_(VBP,PRP)': 0.007194244604316547,\n",
       "  'BIPOS_(VBZ,,)': 0.02158273381294964,\n",
       "  'BIPOS_(VBZ,DT)': 0.014388489208633094,\n",
       "  'BIPOS_(VBZ,NN)': 0.02877697841726619,\n",
       "  'BIPOS_(VBZ,NNP)': 0.014388489208633094,\n",
       "  'BIPOS_(VBZ,PRP$)': 0.02877697841726619,\n",
       "  'BIPOS_(VBZ,PRP)': 0.014388489208633094,\n",
       "  'BIPOS_(VBZ,RP)': 0.014388489208633094,\n",
       "  'BIPOS_(VBZ,VBN)': 0.014388489208633094,\n",
       "  'BIPOS_(WRB,PRP)': 0.007194244604316547,\n",
       "  'BI_(!,”)': 0.007194244604316547,\n",
       "  \"BI_(',”)\": 0.007194244604316547,\n",
       "  'BI_(,,are)': 0.007194244604316547,\n",
       "  'BI_(,,bangs)': 0.007194244604316547,\n",
       "  'BI_(,,my)': 0.007194244604316547,\n",
       "  'BI_(,,so)': 0.007194244604316547,\n",
       "  'BI_(,,“)': 0.04316546762589928,\n",
       "  'BI_(,,”)': 0.007194244604316547,\n",
       "  'BI_(.,“)': 0.007194244604316547,\n",
       "  \"BI_(?,')\": 0.007194244604316547,\n",
       "  'BI_(?,”)': 0.007194244604316547,\n",
       "  'BI_(a,little)': 0.007194244604316547,\n",
       "  'BI_(a,sunday)': 0.007194244604316547,\n",
       "  'BI_(about,jesus)': 0.007194244604316547,\n",
       "  'BI_(and,asks)': 0.007194244604316547,\n",
       "  'BI_(and,blurts)': 0.007194244604316547,\n",
       "  'BI_(and,says)': 0.014388489208633094,\n",
       "  'BI_(and,yells)': 0.007194244604316547,\n",
       "  'BI_(answer,and)': 0.007194244604316547,\n",
       "  'BI_(answers,,)': 0.007194244604316547,\n",
       "  'BI_(are,you)': 0.007194244604316547,\n",
       "  'BI_(asks,his)': 0.007194244604316547,\n",
       "  'BI_(asks,little)': 0.007194244604316547,\n",
       "  'BI_(bangs,on)': 0.007194244604316547,\n",
       "  'BI_(bathroom,!)': 0.007194244604316547,\n",
       "  'BI_(bathroom,door)': 0.007194244604316547,\n",
       "  'BI_(be,a)': 0.007194244604316547,\n",
       "  'BI_(blurts,out)': 0.007194244604316547,\n",
       "  'BI_(brian,raises)': 0.014388489208633094,\n",
       "  'BI_(by,this)': 0.007194244604316547,\n",
       "  'BI_(christ,,)': 0.007194244604316547,\n",
       "  'BI_(class,,)': 0.007194244604316547,\n",
       "  'BI_(concerned,that)': 0.007194244604316547,\n",
       "  'BI_(confused,about)': 0.007194244604316547,\n",
       "  'BI_(dad,gets)': 0.007194244604316547,\n",
       "  'BI_(door,and)': 0.007194244604316547,\n",
       "  'BI_(every,morning)': 0.007194244604316547,\n",
       "  'BI_(furiously,and)': 0.007194244604316547,\n",
       "  'BI_(gets,up)': 0.007194244604316547,\n",
       "  'BI_(hand,and)': 0.014388489208633094,\n",
       "  'BI_(hand,furiously)': 0.007194244604316547,\n",
       "  'BI_(he,asks)': 0.007194244604316547,\n",
       "  'BI_(he,knows)': 0.007194244604316547,\n",
       "  'BI_(he,’)': 0.02877697841726619,\n",
       "  'BI_(heart.,”)': 0.007194244604316547,\n",
       "  'BI_(heaven.,”)': 0.014388489208633094,\n",
       "  'BI_(his,class)': 0.007194244604316547,\n",
       "  'BI_(his,hand)': 0.02158273381294964,\n",
       "  'BI_(his,students)': 0.007194244604316547,\n",
       "  'BI_(how,he)': 0.007194244604316547,\n",
       "  'BI_(in,heaven.)': 0.014388489208633094,\n",
       "  'BI_(in,my)': 0.007194244604316547,\n",
       "  'BI_(in,our)': 0.007194244604316547,\n",
       "  'BI_(in,there)': 0.007194244604316547,\n",
       "  'BI_(is,concerned)': 0.007194244604316547,\n",
       "  'BI_(is,jesus)': 0.007194244604316547,\n",
       "  'BI_(is,surprised)': 0.007194244604316547,\n",
       "  'BI_(jesus,,)': 0.007194244604316547,\n",
       "  'BI_(jesus,christ)': 0.007194244604316547,\n",
       "  'BI_(jesus,today)': 0.007194244604316547,\n",
       "  'BI_(johnny,how)': 0.007194244604316547,\n",
       "  'BI_(johnny,says)': 0.007194244604316547,\n",
       "  'BI_(johnny,waves)': 0.007194244604316547,\n",
       "  'BI_(knows,this)': 0.007194244604316547,\n",
       "  'BI_(little,confused)': 0.007194244604316547,\n",
       "  'BI_(little,johnny)': 0.02158273381294964,\n",
       "  'BI_(might,be)': 0.007194244604316547,\n",
       "  'BI_(morning,,)': 0.007194244604316547,\n",
       "  'BI_(my,dad)': 0.007194244604316547,\n",
       "  'BI_(my,heart.)': 0.007194244604316547,\n",
       "  'BI_(on,the)': 0.007194244604316547,\n",
       "  'BI_(our,bathroom)': 0.007194244604316547,\n",
       "  'BI_(out,,)': 0.007194244604316547,\n",
       "  'BI_(raises,his)': 0.014388489208633094,\n",
       "  'BI_(s,in)': 0.02877697841726619,\n",
       "  'BI_(says,,)': 0.02158273381294964,\n",
       "  'BI_(school,teacher)': 0.007194244604316547,\n",
       "  'BI_(so,he)': 0.007194244604316547,\n",
       "  'BI_(still,in)': 0.007194244604316547,\n",
       "  'BI_(students,might)': 0.007194244604316547,\n",
       "  'BI_(sunday,school)': 0.007194244604316547,\n",
       "  'BI_(surprised,by)': 0.007194244604316547,\n",
       "  'BI_(susan,answers)': 0.007194244604316547,\n",
       "  'BI_(teacher,is)': 0.014388489208633094,\n",
       "  'BI_(that,his)': 0.007194244604316547,\n",
       "  'BI_(the,bathroom)': 0.007194244604316547,\n",
       "  'BI_(the,teacher)': 0.007194244604316547,\n",
       "  'BI_(there,?)': 0.007194244604316547,\n",
       "  'BI_(this,.)': 0.007194244604316547,\n",
       "  'BI_(this,answer)': 0.007194244604316547,\n",
       "  'BI_(today,?)': 0.007194244604316547,\n",
       "  'BI_(up,,)': 0.007194244604316547,\n",
       "  'BI_(waves,his)': 0.007194244604316547,\n",
       "  'BI_(well,,)': 0.007194244604316547,\n",
       "  'BI_(where,is)': 0.007194244604316547,\n",
       "  'BI_(yells,‘)': 0.007194244604316547,\n",
       "  'BI_(you,still)': 0.007194244604316547,\n",
       "  'BI_(‘,jesus)': 0.007194244604316547,\n",
       "  'BI_(’,s)': 0.02877697841726619,\n",
       "  'BI_(“,every)': 0.007194244604316547,\n",
       "  'BI_(“,he)': 0.02877697841726619,\n",
       "  'BI_(“,well)': 0.007194244604316547,\n",
       "  'BI_(“,where)': 0.007194244604316547,\n",
       "  'BI_(”,a)': 0.007194244604316547,\n",
       "  'BI_(”,brian)': 0.007194244604316547,\n",
       "  'BI_(”,little)': 0.014388489208633094,\n",
       "  'BI_(”,susan)': 0.007194244604316547,\n",
       "  'BI_(”,the)': 0.007194244604316547,\n",
       "  'UNIPOS_,': 0.07857142857142857,\n",
       "  'UNIPOS_.': 0.02857142857142857,\n",
       "  'UNIPOS_CC': 0.03571428571428571,\n",
       "  'UNIPOS_DT': 0.05,\n",
       "  'UNIPOS_IN': 0.07857142857142857,\n",
       "  'UNIPOS_JJ': 0.03571428571428571,\n",
       "  'UNIPOS_MD': 0.007142857142857143,\n",
       "  'UNIPOS_NN': 0.14285714285714285,\n",
       "  'UNIPOS_NNP': 0.15714285714285714,\n",
       "  'UNIPOS_NNS': 0.02857142857142857,\n",
       "  'UNIPOS_POS': 0.007142857142857143,\n",
       "  'UNIPOS_PRP': 0.05,\n",
       "  'UNIPOS_PRP$': 0.05714285714285714,\n",
       "  'UNIPOS_RB': 0.02857142857142857,\n",
       "  'UNIPOS_RP': 0.014285714285714285,\n",
       "  'UNIPOS_VB': 0.007142857142857143,\n",
       "  'UNIPOS_VBN': 0.014285714285714285,\n",
       "  'UNIPOS_VBP': 0.02142857142857143,\n",
       "  'UNIPOS_VBZ': 0.15,\n",
       "  'UNIPOS_WRB': 0.007142857142857143,\n",
       "  'UNI_!': 0.007142857142857143,\n",
       "  \"UNI_'\": 0.007142857142857143,\n",
       "  'UNI_,': 0.07857142857142857,\n",
       "  'UNI_.': 0.007142857142857143,\n",
       "  'UNI_?': 0.014285714285714285,\n",
       "  'UNI_a': 0.014285714285714285,\n",
       "  'UNI_about': 0.007142857142857143,\n",
       "  'UNI_and': 0.03571428571428571,\n",
       "  'UNI_answer': 0.007142857142857143,\n",
       "  'UNI_answers': 0.007142857142857143,\n",
       "  'UNI_are': 0.007142857142857143,\n",
       "  'UNI_asks': 0.014285714285714285,\n",
       "  'UNI_bangs': 0.007142857142857143,\n",
       "  'UNI_bathroom': 0.014285714285714285,\n",
       "  'UNI_be': 0.007142857142857143,\n",
       "  'UNI_blurts': 0.007142857142857143,\n",
       "  'UNI_brian': 0.014285714285714285,\n",
       "  'UNI_by': 0.007142857142857143,\n",
       "  'UNI_christ': 0.007142857142857143,\n",
       "  'UNI_class': 0.007142857142857143,\n",
       "  'UNI_concerned': 0.007142857142857143,\n",
       "  'UNI_confused': 0.007142857142857143,\n",
       "  'UNI_dad': 0.007142857142857143,\n",
       "  'UNI_door': 0.007142857142857143,\n",
       "  'UNI_every': 0.007142857142857143,\n",
       "  'UNI_furiously': 0.007142857142857143,\n",
       "  'UNI_gets': 0.007142857142857143,\n",
       "  'UNI_hand': 0.02142857142857143,\n",
       "  'UNI_he': 0.04285714285714286,\n",
       "  'UNI_heart.': 0.007142857142857143,\n",
       "  'UNI_heaven.': 0.014285714285714285,\n",
       "  'UNI_his': 0.03571428571428571,\n",
       "  'UNI_how': 0.007142857142857143,\n",
       "  'UNI_in': 0.03571428571428571,\n",
       "  'UNI_is': 0.02142857142857143,\n",
       "  'UNI_jesus': 0.02142857142857143,\n",
       "  'UNI_johnny': 0.02142857142857143,\n",
       "  'UNI_knows': 0.007142857142857143,\n",
       "  'UNI_little': 0.02857142857142857,\n",
       "  'UNI_might': 0.007142857142857143,\n",
       "  'UNI_morning': 0.007142857142857143,\n",
       "  'UNI_my': 0.014285714285714285,\n",
       "  'UNI_on': 0.007142857142857143,\n",
       "  'UNI_our': 0.007142857142857143,\n",
       "  'UNI_out': 0.007142857142857143,\n",
       "  'UNI_raises': 0.014285714285714285,\n",
       "  'UNI_s': 0.02857142857142857,\n",
       "  'UNI_says': 0.02142857142857143,\n",
       "  'UNI_school': 0.007142857142857143,\n",
       "  'UNI_so': 0.007142857142857143,\n",
       "  'UNI_still': 0.007142857142857143,\n",
       "  'UNI_students': 0.007142857142857143,\n",
       "  'UNI_sunday': 0.007142857142857143,\n",
       "  'UNI_surprised': 0.007142857142857143,\n",
       "  'UNI_susan': 0.007142857142857143,\n",
       "  'UNI_teacher': 0.014285714285714285,\n",
       "  'UNI_that': 0.007142857142857143,\n",
       "  'UNI_the': 0.014285714285714285,\n",
       "  'UNI_there': 0.007142857142857143,\n",
       "  'UNI_this': 0.014285714285714285,\n",
       "  'UNI_today': 0.007142857142857143,\n",
       "  'UNI_up': 0.007142857142857143,\n",
       "  'UNI_waves': 0.007142857142857143,\n",
       "  'UNI_well': 0.007142857142857143,\n",
       "  'UNI_where': 0.007142857142857143,\n",
       "  'UNI_yells': 0.007142857142857143,\n",
       "  'UNI_you': 0.007142857142857143,\n",
       "  'UNI_‘': 0.007142857142857143,\n",
       "  'UNI_’': 0.02857142857142857,\n",
       "  'UNI_“': 0.05,\n",
       "  'UNI_”': 0.05},\n",
       " 'funny')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funny_feature_tuples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = funny_feature_tuples[:1600]+unfunny_feature_tuples[:1600]\n",
    "dev = funny_feature_tuples[1600:]+unfunny_feature_tuples[1600:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = nltk.classify.NaiveBayesClassifier.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50875"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = nltk.classify.accuracy(classifier, dev)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        |       u |\n",
      "        |       n |\n",
      "        |   f   f |\n",
      "        |   u   u |\n",
      "        |   n   n |\n",
      "        |   n   n |\n",
      "        |   y   y |\n",
      "--------+---------+\n",
      "  funny |<157>243 |\n",
      "unfunny | 150<250>|\n",
      "--------+---------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_only = []\n",
    "labels_only = []\n",
    "for vector, label in dev:\n",
    "    features_only.append(vector)\n",
    "    labels_only.append(label)\n",
    "    \n",
    "\n",
    "predicted_labels = classifier.classify_many(features_only)\n",
    "\n",
    "confusion_matrix = nltk.ConfusionMatrix(labels_only, predicted_labels)\n",
    "print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
