{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funnynet\n",
    "\n",
    "## A neural network that makes jokes\n",
    "\n",
    "Special thanks to taivop for providing the [dataset](https://github.com/taivop/joke-dataset).\n",
    "\n",
    "This notebook is heavily inspired by [fastai NLP work](https://github.com/fastai/fastai/blob/master/courses/dl2/imdb.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "EOJ = 'xeoj'  # end of joke tag\n",
    "\n",
    "PATH=Path('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('data/stupidstuff.json'), PosixPath('data/reddit_jokes.json')]\n"
     ]
    }
   ],
   "source": [
    "files = list(PATH.iterdir())\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in files:\n",
    "    if \"eddit\" in str(fname):\n",
    "        reddit_dataset = str(fname)\n",
    "    if \"upid\" in str(fname):\n",
    "        stupid_dataset = str(fname)\n",
    "reddit_jokes = json.load(open(reddit_dataset))\n",
    "stupid_jokes = json.load(open(stupid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194553"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reddit_jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'body': 'Now I have to say \"Leroy can you please paint the fence?\"',\n",
       " 'id': '5tz52q',\n",
       " 'score': 1,\n",
       " 'title': 'I hate how you cant even say black paint anymore'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_jokes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's discard all the jokes that have 0 score, as they aren't that helpful for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rated_jokes = [joke for joke in reddit_jokes if joke['score'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132992"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rated_jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172.94791416025024, 48526)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = [joke['score'] for joke in rated_jokes]\n",
    "np.mean(scores),np.max(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many jokes have really high scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1067"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([score for score in scores if score>5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAD8CAYAAACyyUlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAFJlJREFUeJzt3X+MndWd3/H3p3YgbLLEBoaI2qh2FKtdg7YNsQjbVKsIKjAQxfwRJKNVsbJIVrOkzbaVNqaRipoECXarkkVNskLBjYnSGMpmhZWYei1ClFYNP4ZAAEOIJ4bCFBo7tWHZRgnr7Ld/3DPkeri24zk2c22/X9LVPc/3Oc9zz7HuzGeeH/c6VYUkST3+znwPQJJ0/DNMJEndDBNJUjfDRJLUzTCRJHUzTCRJ3QwTSVI3w0SS1M0wkSR1WzjfAzjazjrrrFq2bNl8D0OSjiuPPvroT6tqYq7bn3BhsmzZMiYnJ+d7GJJ0XEnyv3q29zSXJKmbYSJJ6maYSJK6GSaSpG6GiSSpm2EiSepmmEiSuhkmkqRuhokkqdsJ9wn4Hss2fOuN9vM3XzmPI5Gk44tHJpKkboaJJKmbYSJJ6maYSJK6GSaSpG6GiSSp22HDJMnGJLuTPDVU+5MkP0zyRJK/SLJoaN0NSaaSPJvksqH66labSrJhqL48yUNJdia5K8kprX5qW55q65cdrUlLko6uX+fI5CvA6lm17cD5VfXbwI+AGwCSrATWAue1bb6YZEGSBcAXgMuBlcA1rS/ALcCtVbUC2Adc1+rXAfuq6r3Ara2fJGkMHTZMquq7wN5Ztb+sqv1t8UFgaWuvATZX1S+q6jlgCriwPaaqaldVvQ5sBtYkCXAxcE/bfhNw1dC+NrX2PcAlrb8kacwcjWsmvw/c19pLgBeH1k232sHqZwKvDAXTTP2AfbX1r7b+kqQx0xUmST4N7Ae+NlMa0a3mUD/UvkaNY32SySSTe/bsOfSgJUlH3ZzDJMk64MPA71XVzC/5aeDcoW5LgZcOUf8psCjJwln1A/bV1r+LWafbZlTV7VW1qqpWTUxMzHVKkqQ5mlOYJFkNfAr4SFX9bGjVFmBtuxNrObACeBh4BFjR7tw6hcFF+i0thB4APtq2XwfcO7Svda39UeDbQ6ElSRojh/3W4CRfBz4EnJVkGriRwd1bpwLb2zXxB6vqn1fVjiR3A08zOP11fVX9su3nE8A2YAGwsap2tJf4FLA5yeeAx4A7Wv0O4KtJphgckaw9CvOVJB0Dhw2TqrpmRPmOEbWZ/jcBN42obwW2jqjvYnC31+z6z4GrDzc+SdL88xPwkqRuhokkqZthIknqZphIkroZJpKkboaJJKmbYSJJ6maYSJK6GSaSpG6GiSSpm2EiSepmmEiSuhkmkqRuhokkqZthIknqZphIkroZJpKkboaJJKmbYSJJ6maYSJK6GSaSpG6GiSSpm2EiSepmmEiSuh02TJJsTLI7yVNDtTOSbE+ysz0vbvUkuS3JVJInklwwtM261n9nknVD9fcnebJtc1uSHOo1JEnj59c5MvkKsHpWbQNwf1WtAO5vywCXAyvaYz3wJRgEA3Aj8AHgQuDGoXD4Uus7s93qw7yGJGnMHDZMquq7wN5Z5TXAptbeBFw1VL+zBh4EFiU5B7gM2F5Ve6tqH7AdWN3WnV5V36uqAu6cta9RryFJGjNzvWby7qp6GaA9n93qS4AXh/pNt9qh6tMj6od6jTdJsj7JZJLJPXv2zHFKkqS5OtoX4DOiVnOoH5Gqur2qVlXVqomJiSPdXJLUaa5h8pN2ior2vLvVp4Fzh/otBV46TH3piPqhXkOSNGbmGiZbgJk7stYB9w7Vr213dV0EvNpOUW0DLk2yuF14vxTY1ta9luSidhfXtbP2Neo1JEljZuHhOiT5OvAh4Kwk0wzuyroZuDvJdcALwNWt+1bgCmAK+BnwMYCq2pvks8Ajrd9nqmrmov7HGdwxdhpwX3twiNeQJI2Zw4ZJVV1zkFWXjOhbwPUH2c9GYOOI+iRw/oj6/x31GpKk8eMn4CVJ3QwTSVI3w0SS1M0wkSR1M0wkSd0ME0lSN8NEktTNMJEkdTNMJEndDBNJUjfDRJLUzTCRJHUzTCRJ3QwTSVI3w0SS1M0wkSR1M0wkSd0ME0lSN8NEktTNMJEkdTNMJEndDBNJUjfDRJLUrStMkvyrJDuSPJXk60nenmR5koeS7ExyV5JTWt9T2/JUW79saD83tPqzSS4bqq9utakkG3rGKkk6duYcJkmWAP8SWFVV5wMLgLXALcCtVbUC2Adc1za5DthXVe8Fbm39SLKybXcesBr4YpIFSRYAXwAuB1YC17S+kqQx03uaayFwWpKFwG8ALwMXA/e09ZuAq1p7TVumrb8kSVp9c1X9oqqeA6aAC9tjqqp2VdXrwObWV5I0ZuYcJlX1v4H/ALzAIEReBR4FXqmq/a3bNLCktZcAL7Zt97f+Zw7XZ21zsLokacz0nOZazOBIYTnwd4F3MDglNVvNbHKQdUdaHzWW9Ukmk0zu2bPncEOXJB1lPae5/inwXFXtqaq/Ab4B/GNgUTvtBbAUeKm1p4FzAdr6dwF7h+uztjlY/U2q6vaqWlVVqyYmJjqmJEmai54weQG4KMlvtGsflwBPAw8AH2191gH3tvaWtkxb/+2qqlZf2+72Wg6sAB4GHgFWtLvDTmFwkX5Lx3glScfIwsN3Ga2qHkpyD/B9YD/wGHA78C1gc5LPtdodbZM7gK8mmWJwRLK27WdHkrsZBNF+4Pqq+iVAkk8A2xjcKbaxqnbMdbySpGNnzmECUFU3AjfOKu9icCfW7L4/B64+yH5uAm4aUd8KbO0ZoyTp2PMT8JKkboaJJKmbYSJJ6maYSJK6GSaSpG6GiSSpm2EiSepmmEiSuhkmkqRuhokkqZthIknqZphIkroZJpKkboaJJKmbYSJJ6maYSJK6GSaSpG6GiSSpm2EiSepmmEiSuhkmkqRuhokkqZthIknqZphIkrp1hUmSRUnuSfLDJM8k+Z0kZyTZnmRne17c+ibJbUmmkjyR5IKh/axr/XcmWTdUf3+SJ9s2tyVJz3glScdG75HJnwL/rar+AfAPgWeADcD9VbUCuL8tA1wOrGiP9cCXAJKcAdwIfAC4ELhxJoBan/VD263uHK8k6RiYc5gkOR34XeAOgKp6vapeAdYAm1q3TcBVrb0GuLMGHgQWJTkHuAzYXlV7q2ofsB1Y3dadXlXfq6oC7hzalyRpjPQcmbwH2AP85ySPJflykncA766qlwHa89mt/xLgxaHtp1vtUPXpEXVJ0pjpCZOFwAXAl6rqfcD/41entEYZdb2j5lB/846T9Ukmk0zu2bPn0KOWJB11PWEyDUxX1UNt+R4G4fKTdoqK9rx7qP+5Q9svBV46TH3piPqbVNXtVbWqqlZNTEx0TEmSNBdzDpOq+j/Ai0n+fitdAjwNbAFm7shaB9zb2luAa9tdXRcBr7bTYNuAS5MsbhfeLwW2tXWvJbmo3cV17dC+JEljZGHn9v8C+FqSU4BdwMcYBNTdSa4DXgCubn23AlcAU8DPWl+qam+SzwKPtH6fqaq9rf1x4CvAacB97SFJGjNdYVJVjwOrRqy6ZETfAq4/yH42AhtH1CeB83vGKEk69vwEvCSpm2EiSepmmEiSuhkmkqRuhokkqZthIknqZphIkroZJpKkboaJJKmbYSJJ6maYSJK6GSaSpG6GiSSpm2EiSepmmEiSuhkmkqRuhokkqZthIknqZphIkroZJpKkboaJJKmbYSJJ6maYSJK6GSaSpG7dYZJkQZLHknyzLS9P8lCSnUnuSnJKq5/alqfa+mVD+7ih1Z9NctlQfXWrTSXZ0DtWSdKxcTSOTD4JPDO0fAtwa1WtAPYB17X6dcC+qnovcGvrR5KVwFrgPGA18MUWUAuALwCXAyuBa1pfSdKY6QqTJEuBK4Evt+UAFwP3tC6bgKtae01bpq2/pPVfA2yuql9U1XPAFHBhe0xV1a6qeh3Y3PpKksZM75HJ54E/Av62LZ8JvFJV+9vyNLCktZcALwK09a+2/m/UZ21zsPqbJFmfZDLJ5J49ezqnJEk6UnMOkyQfBnZX1aPD5RFd6zDrjrT+5mLV7VW1qqpWTUxMHGLUkqRjYWHHth8EPpLkCuDtwOkMjlQWJVnYjj6WAi+1/tPAucB0koXAu4C9Q/UZw9scrC5JGiNzPjKpqhuqamlVLWNwAf3bVfV7wAPAR1u3dcC9rb2lLdPWf7uqqtXXtru9lgMrgIeBR4AV7e6wU9prbJnreCVJx07PkcnBfArYnORzwGPAHa1+B/DVJFMMjkjWAlTVjiR3A08D+4Hrq+qXAEk+AWwDFgAbq2rHMRivJKnTUQmTqvoO8J3W3sXgTqzZfX4OXH2Q7W8CbhpR3wpsPRpjlCQdO34CXpLUzTCRJHUzTCRJ3QwTSVI3w0SS1M0wkSR1M0wkSd0ME0lSN8NEktTNMJEkdTNMJEndDBNJUjfDRJLUzTCRJHUzTCRJ3QwTSVI3w0SS1M0wkSR1M0wkSd0ME0lSN8NEktTNMJEkdTNMJEnd5hwmSc5N8kCSZ5LsSPLJVj8jyfYkO9vz4lZPktuSTCV5IskFQ/ta1/rvTLJuqP7+JE+2bW5Lkp7JSpKOjZ4jk/3Av6mq3wIuAq5PshLYANxfVSuA+9sywOXAivZYD3wJBuED3Ah8ALgQuHEmgFqf9UPbre4YryTpGJlzmFTVy1X1/dZ+DXgGWAKsATa1bpuAq1p7DXBnDTwILEpyDnAZsL2q9lbVPmA7sLqtO72qvldVBdw5tC9J0hg5KtdMkiwD3gc8BLy7ql6GQeAAZ7duS4AXhzabbrVD1adH1CVJY6Y7TJK8E/hz4A+r6q8O1XVEreZQHzWG9Ukmk0zu2bPncEOWJB1lXWGS5G0MguRrVfWNVv5JO0VFe97d6tPAuUObLwVeOkx96Yj6m1TV7VW1qqpWTUxM9ExJkjQHPXdzBbgDeKaq/uPQqi3AzB1Z64B7h+rXtru6LgJebafBtgGXJlncLrxfCmxr615LclF7rWuH9iVJGiMLO7b9IPDPgCeTPN5q/xa4Gbg7yXXAC8DVbd1W4ApgCvgZ8DGAqtqb5LPAI63fZ6pqb2t/HPgKcBpwX3tIksbMnMOkqv4Ho69rAFwyon8B1x9kXxuBjSPqk8D5cx2jJOmt4SfgJUndDBNJUjfDRJLUzTCRJHUzTCRJ3QwTSVI3w0SS1M0wkSR1M0wkSd0ME0lSN8NEktTNMJEkdTNMJEndDBNJUjfDRJLUzTCRJHUzTCRJ3QwTSVI3w0SS1M0wkSR1M0wkSd0ME0lSN8NEktTNMJEkdVs43wM4nCSrgT8FFgBfrqqb34rXXbbhW2+0n7/5yrfiJSXpuDXWRyZJFgBfAC4HVgLXJFk5v6OSJM027kcmFwJTVbULIMlmYA3w9Fs5CI9SJOnQxj1MlgAvDi1PAx+Yp7EABwbLMENG0sls3MMkI2r1pk7JemB9W/zrJM/O8fXOAn46lw1zyxxfcXzMee4ngJN17ifrvMG5j5r73+vZ6biHyTRw7tDyUuCl2Z2q6nbg9t4XSzJZVat693M8cu4n39xP1nmDcz8Wcx/rC/DAI8CKJMuTnAKsBbbM85gkSbOM9ZFJVe1P8glgG4NbgzdW1Y55HpYkaZaxDhOAqtoKbH2LXq77VNlxzLmffE7WeYNzP+pS9abr2ZIkHZFxv2YiSToOGCZNktVJnk0ylWTDfI9nLpJsTLI7yVNDtTOSbE+ysz0vbvUkua3N94kkFwxts67135lk3VD9/UmebNvclmTUrdvzIsm5SR5I8kySHUk+2eon9PyTvD3Jw0l+0Ob971t9eZKH2hzuajewkOTUtjzV1i8b2tcNrf5sksuG6mP9s5FkQZLHknyzLZ8Uc0/yfHs/Pp5kstXm7/1eVSf9g8HF/R8D7wFOAX4ArJzvcc1hHr8LXAA8NVT7Y2BDa28AbmntK4D7GHyW5yLgoVY/A9jVnhe39uK27mHgd9o29wGXz/ech+Z5DnBBa/8m8CMGX8FzQs+/jeWdrf024KE2n7uBta3+Z8DHW/sPgD9r7bXAXa29sr3vTwWWt5+HBcfDzwbwr4H/AnyzLZ8UcweeB86aVZu397tHJgNvfG1LVb0OzHxty3Glqr4L7J1VXgNsau1NwFVD9Ttr4EFgUZJzgMuA7VW1t6r2AduB1W3d6VX1vRq80+4c2te8q6qXq+r7rf0a8AyDb1A4oeffxv/XbfFt7VHAxcA9rT573jP/HvcAl7S/ONcAm6vqF1X1HDDF4OdirH82kiwFrgS+3JbDSTL3g5i397thMjDqa1uWzNNYjrZ3V9XLMPiFC5zd6geb86Hq0yPqY6edvngfg7/ST/j5t9M8jwO7Gfwy+DHwSlXtb12Gx/rG/Nr6V4EzOfJ/j3HxeeCPgL9ty2dy8sy9gL9M8mgG3wIC8/h+H/tbg98iv9bXtpxgDjbnI62PlSTvBP4c+MOq+qtDnOY9YeZfVb8E/lGSRcBfAL81qlt7PtL5jfqDcyzmneTDwO6qejTJh2bKI7qecHNvPlhVLyU5G9ie5IeH6HvM3+8emQz8Wl/bcpz6STtkpT3vbvWDzflQ9aUj6mMjydsYBMnXquobrXzSzL+qXgG+w+Cc+KIkM38sDo/1jfm19e9icGr0SP89xsEHgY8keZ7BKaiLGRypnAxzp6peas+7GfwRcSHz+X6f74tI4/BgcIS2i8HFt5kLbefN97jmOJdlHHgB/k848ILcH7f2lRx4Qe7h+tUFuecYXIxb3NpntHWPtL4zF+SumO/5Ds0zDM7rfn5W/YSePzABLGrt04D/DnwY+K8ceBH6D1r7eg68CH13a5/HgRehdzG4AH1c/GwAH+JXF+BP+LkD7wB+c6j9P4HV8/l+n/d/lHF5MLjb4UcMzjd/er7HM8c5fB14GfgbBn9ZXMfgnPD9wM72PPNGCYP/eOzHwJPAqqH9/D6Di5BTwMeG6quAp9o2/4n2oddxeAD/hMFh+BPA4+1xxYk+f+C3gcfavJ8C/l2rv4fB3ThT7Zfrqa3+9rY81da/Z2hfn25ze5ahO3eOh58NDgyTE37ubY4/aI8dM2Obz/e7n4CXJHXzmokkqZthIknqZphIkroZJpKkboaJJKmbYSJJ6maYSJK6GSaSpG7/H4e619xsYg+AAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6879ce8828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(scores, bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there's quite a dropoff of scores, almost none above 1000. Score normalization or something might be useful -- a large amount of the score is probably due to posting time, so it might be valuable to batch all the score into \"unpopular\", \"semi-popular\", and \"very popular\" or something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f686cdb5438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "low_scores = [score for score in scores if score<5000]\n",
    "plt.hist(low_scores, bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the Reddit joke score incidences plotted on a log scale on the y axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f686cc26358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "low_scores = [score for score in scores]\n",
    "plt.yscale('log', nonposy='clip')\n",
    "plt.hist(low_scores, bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the Reddit joke score incidences plotted on a log scale on the x axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f686cc84ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "low_scores = [score for score in scores]\n",
    "plt.xscale('log', nonposx='clip')\n",
    "plt.ylim(ymax=200000)\n",
    "#plt.axes.set_ylim([0,200000])\n",
    "plt.hist(low_scores, bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I hate how you cant even say black paint anymore Now I have to say \"Leroy can you please paint the fence?\"'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_body = [joke['title']+' '+joke['body'] for joke in rated_jokes]\n",
    "title_body[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horrible, but formatted correctly. Now, let's combine all the jokes into one long string, using the `EOJ` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAE81JREFUeJzt3W+MXfV95/H3pxBalpbahAEh21pT1cqWIoWABV4hVbvQGkOimAdFAu3WFrLkFSKrRLtS19knVqGRyJOmi5QiWcGL3c2GskkjrGDiWg5RFYl/QyAQcFhPKYWRWTytgcCiJiL97oP5eXvl3zVzPWZ8bc/7JV3dc77ne879HSH0mXPO716nqpAkadAvjXsAkqRTj+EgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkztnjHsB8XXjhhbVy5cpxD0OSThvPPPPM31fVxCi9p204rFy5ksnJyXEPQ5JOG0n+btRebytJkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqn7Tekpbms3PLIuIdwUr16z6fHPQSdQbxykCR15gyHJJ9I8tzA66dJvpDkgiR7kxxo70tbf5Lcm2QqyfNJrhw41sbWfyDJxoH6VUleaPvcmyQLc7qSpFHMGQ5V9XJVXVFVVwBXAe8D3wa2APuqahWwr60D3Aisaq/NwH0ASS4AtgLXAFcDW48ESuvZPLDfuo/k7CRJ83K8t5WuB/6mqv4OWA/saPUdwM1teT2ws2Y9ASxJcglwA7C3qg5X1VvAXmBd23Z+VT1eVQXsHDiWJGkMjjccbgW+0ZYvrqo3ANr7Ra2+DHh9YJ/pVvuw+vSQuiRpTEYOhyTnAJ8F/tdcrUNqNY/6sDFsTjKZZHJmZmaOYUiS5ut4rhxuBH5YVW+29TfbLSHa+6FWnwZWDOy3HDg4R335kHqnqrZV1eqqWj0xMdI/ZiRJmofjCYfb+OdbSgC7gCMzjjYCDw/UN7RZS2uAd9ptpz3A2iRL24PotcCetu3dJGvaLKUNA8eSJI3BSF+CS/IvgN8D/sNA+R7goSSbgNeAW1p9N3ATMMXszKbbAarqcJK7gadb311Vdbgt3wE8AJwLPNpekqQxGSkcqup94ONH1f6B2dlLR/cWcOcxjrMd2D6kPglcPspYJEkLz29IS5I6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqTNSOCRZkuSbSX6SZH+Sf53kgiR7kxxo70tbb5Lcm2QqyfNJrhw4zsbWfyDJxoH6VUleaPvcmyQf/alKkkY16pXDfwO+W1X/CvgksB/YAuyrqlXAvrYOcCOwqr02A/cBJLkA2ApcA1wNbD0SKK1n88B+607stCRJJ2LOcEhyPvA7wP0AVfXzqnobWA/saG07gJvb8npgZ816AliS5BLgBmBvVR2uqreAvcC6tu38qnq8qgrYOXAsSdIYjHLl8BvADPDfkzyb5GtJzgMurqo3ANr7Ra1/GfD6wP7TrfZh9ekhdUnSmIwSDmcDVwL3VdWngP/LP99CGmbY84KaR70/cLI5yWSSyZmZmQ8ftSRp3kYJh2lguqqebOvfZDYs3my3hGjvhwb6Vwzsvxw4OEd9+ZB6p6q2VdXqqlo9MTExwtAlSfMxZzhU1f8BXk/yiVa6HngJ2AUcmXG0EXi4Le8CNrRZS2uAd9ptpz3A2iRL24PotcCetu3dJGvaLKUNA8eSJI3B2SP2/Ufg60nOAV4Bbmc2WB5Ksgl4Dbil9e4GbgKmgPdbL1V1OMndwNOt766qOtyW7wAeAM4FHm0vSdKYjBQOVfUcsHrIpuuH9BZw5zGOsx3YPqQ+CVw+ylgkSQvPb0hLkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpM1I4JHk1yQtJnksy2WoXJNmb5EB7X9rqSXJvkqkkzye5cuA4G1v/gSQbB+pXteNPtX3zUZ+oJGl0x3Pl8G+r6oqqWt3WtwD7qmoVsK+tA9wIrGqvzcB9MBsmwFbgGuBqYOuRQGk9mwf2WzfvM5IknbATua20HtjRlncANw/Ud9asJ4AlSS4BbgD2VtXhqnoL2Ausa9vOr6rHq6qAnQPHkiSNwajhUMBfJXkmyeZWu7iq3gBo7xe1+jLg9YF9p1vtw+rTQ+qdJJuTTCaZnJmZGXHokqTjdfaIfddW1cEkFwF7k/zkQ3qHPS+oedT7YtU2YBvA6tWrh/ZIkk7cSFcOVXWwvR8Cvs3sM4M32y0h2vuh1j4NrBjYfTlwcI768iF1SdKYzBkOSc5L8mtHloG1wI+BXcCRGUcbgYfb8i5gQ5u1tAZ4p9122gOsTbK0PYheC+xp295NsqbNUtowcCxJ0hiMclvpYuDbbXbp2cD/rKrvJnkaeCjJJuA14JbWvxu4CZgC3gduB6iqw0nuBp5ufXdV1eG2fAfwAHAu8Gh7SZLGZM5wqKpXgE8Oqf8DcP2QegF3HuNY24HtQ+qTwOUjjFeSdBL4DWlJUmfU2Uo6za3c8si4hyDpNOKVgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpM3I4JDkrybNJvtPWL03yZJIDSf4iyTmt/sttfaptXzlwjC+2+stJbhior2u1qSRbPrrTkyTNx/FcOXwe2D+w/mXgK1W1CngL2NTqm4C3quo3ga+0PpJcBtwK/DawDvizFjhnAV8FbgQuA25rvZKkMRkpHJIsBz4NfK2tB7gO+GZr2QHc3JbXt3Xa9utb/3rgwar6WVX9LTAFXN1eU1X1SlX9HHiw9UqSxmTUK4c/Bf4Q+Ke2/nHg7ar6oK1PA8va8jLgdYC2/Z3W///rR+1zrLokaUzmDIcknwEOVdUzg+UhrTXHtuOtDxvL5iSTSSZnZmY+ZNSSpBMxypXDtcBnk7zK7C2f65i9kliS5OzWsxw42JangRUAbfuvA4cH60ftc6x6p6q2VdXqqlo9MTExwtAlSfMxZzhU1ReranlVrWT2gfL3qurfAY8Bv9/aNgIPt+VdbZ22/XtVVa1+a5vNdCmwCngKeBpY1WY/ndM+Y9dHcnaSpHk5e+6WY/ovwINJ/hh4Fri/1e8H/jzJFLNXDLcCVNWLSR4CXgI+AO6sql8AJPkcsAc4C9heVS+ewLgkSSfouMKhqr4PfL8tv8LsTKOje/4RuOUY+38J+NKQ+m5g9/GMRZK0cPyGtCSpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjon8g1pSRqrlVseGfcQTrpX7/n0SfkcrxwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSZ05wyHJryR5KsmPkryY5I9a/dIkTyY5kOQvkpzT6r/c1qfa9pUDx/piq7+c5IaB+rpWm0qy5aM/TUnS8RjlyuFnwHVV9UngCmBdkjXAl4GvVNUq4C1gU+vfBLxVVb8JfKX1keQy4Fbgt4F1wJ8lOSvJWcBXgRuBy4DbWq8kaUzmDIea9V5b/Vh7FXAd8M1W3wHc3JbXt3Xa9uuTpNUfrKqfVdXfAlPA1e01VVWvVNXPgQdbryRpTEZ65tD+wn8OOATsBf4GeLuqPmgt08CytrwMeB2gbX8H+Phg/ah9jlWXJI3JSOFQVb+oqiuA5cz+pf9bw9rae46x7XjrnSSbk0wmmZyZmZl74JKkeTmu2UpV9TbwfWANsCTJkX8saDlwsC1PAysA2vZfBw4P1o/a51j1YZ+/rapWV9XqiYmJ4xm6JOk4jDJbaSLJkrZ8LvC7wH7gMeD3W9tG4OG2vKut07Z/r6qq1W9ts5kuBVYBTwFPA6va7KdzmH1oveujODlJ0vyM8s+EXgLsaLOKfgl4qKq+k+Ql4MEkfww8C9zf+u8H/jzJFLNXDLcCVNWLSR4CXgI+AO6sql8AJPkcsAc4C9heVS9+ZGcoSTpuc4ZDVT0PfGpI/RVmnz8cXf9H4JZjHOtLwJeG1HcDu0cYryTpJPAb0pKkjuEgSeoYDpKkzigPpCWdBlZueWTcQ9AZxCsHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdeYMhyQrkjyWZH+SF5N8vtUvSLI3yYH2vrTVk+TeJFNJnk9y5cCxNrb+A0k2DtSvSvJC2+feJFmIk5UkjWaUK4cPgP9cVb8FrAHuTHIZsAXYV1WrgH1tHeBGYFV7bQbug9kwAbYC1wBXA1uPBErr2Tyw37oTPzVJ0nzNGQ5V9UZV/bAtvwvsB5YB64EdrW0HcHNbXg/srFlPAEuSXALcAOytqsNV9RawF1jXtp1fVY9XVQE7B44lSRqD43rmkGQl8CngSeDiqnoDZgMEuKi1LQNeH9htutU+rD49pD7s8zcnmUwyOTMzczxDlyQdh5HDIcmvAt8CvlBVP/2w1iG1mke9L1Ztq6rVVbV6YmJiriFLkuZppHBI8jFmg+HrVfWXrfxmuyVEez/U6tPAioHdlwMH56gvH1KXJI3JKLOVAtwP7K+qPxnYtAs4MuNoI/DwQH1Dm7W0Bnin3XbaA6xNsrQ9iF4L7Gnb3k2ypn3WhoFjSZLG4OwReq4F/gB4IclzrfZfgXuAh5JsAl4DbmnbdgM3AVPA+8DtAFV1OMndwNOt766qOtyW7wAeAM4FHm0vSdKYzBkOVfUDhj8XALh+SH8Bdx7jWNuB7UPqk8Dlc41FknRy+A1pSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdUb5nsMZZ+WWR8Y9BEk6pXnlIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpM6c4ZBke5JDSX48ULsgyd4kB9r70lZPknuTTCV5PsmVA/tsbP0HkmwcqF+V5IW2z71JjvXvVUuSTpJRrhweANYdVdsC7KuqVcC+tg5wI7CqvTYD98FsmABbgWuAq4GtRwKl9Wwe2O/oz5IknWRzhkNV/TVw+KjyemBHW94B3DxQ31mzngCWJLkEuAHYW1WHq+otYC+wrm07v6oer6oCdg4cS5I0JvN95nBxVb0B0N4vavVlwOsDfdOt9mH16SF1SdIYfdQPpIc9L6h51IcfPNmcZDLJ5MzMzDyHKEmay3zD4c12S4j2fqjVp4EVA33LgYNz1JcPqQ9VVduqanVVrZ6YmJjn0CVJc5lvOOwCjsw42gg8PFDf0GYtrQHeabed9gBrkyxtD6LXAnvatneTrGmzlDYMHEuSNCZz/hvSSb4B/BvgwiTTzM46ugd4KMkm4DXglta+G7gJmALeB24HqKrDSe4Gnm59d1XVkYfcdzA7I+pc4NH2kiSN0ZzhUFW3HWPT9UN6C7jzGMfZDmwfUp8ELp9rHJKkk8dvSEuSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKlzyoRDknVJXk4ylWTLuMcjSYvZKREOSc4CvgrcCFwG3JbksvGOSpIWr1MiHICrgamqeqWqfg48CKwf85gkadE6VcJhGfD6wPp0q0mSxuDscQ+gyZBadU3JZmBzW30vycvz/LwLgb+f576nK8/5zLfYzhcW4Tnnyyd0zv9y1MZTJRymgRUD68uBg0c3VdU2YNuJfliSyapafaLHOZ14zme+xXa+4DkvpFPlttLTwKoklyY5B7gV2DXmMUnSonVKXDlU1QdJPgfsAc4CtlfVi2MeliQtWqdEOABU1W5g90n6uBO+NXUa8pzPfIvtfMFzXjCp6p77SpIWuVPlmYMk6RSyqMJhMf5ER5LtSQ4l+fG4x3IyJFmR5LEk+5O8mOTz4x7TQkvyK0meSvKjds5/NO4xnSxJzkrybJLvjHssJ0OSV5O8kOS5JJML+lmL5bZS+4mO/w38HrNTZ58Gbquql8Y6sAWW5HeA94CdVXX5uMez0JJcAlxSVT9M8mvAM8DNZ/J/5yQBzquq95J8DPgB8PmqemLMQ1twSf4TsBo4v6o+M+7xLLQkrwKrq2rBv9uxmK4cFuVPdFTVXwOHxz2Ok6Wq3qiqH7bld4H9nOHftq9Z77XVj7XXGf9XX5LlwKeBr417LGeixRQO/kTHIpNkJfAp4MnxjmThtdsrzwGHgL1VdcafM/CnwB8C/zTugZxEBfxVkmfaL0YsmMUUDiP9RIfODEl+FfgW8IWq+um4x7PQquoXVXUFs78ucHWSM/oWYpLPAIeq6plxj+Uku7aqrmT2F6zvbLeNF8RiCoeRfqJDp7923/1bwNer6i/HPZ6TqareBr4PrBvzUBbatcBn2z34B4HrkvyP8Q5p4VXVwfZ+CPg2s7fLF8RiCgd/omMRaA9n7wf2V9WfjHs8J0OSiSRL2vK5wO8CPxnvqBZWVX2xqpZX1Upm/1/+XlX9+zEPa0ElOa9NsiDJecBaYMFmIS6acKiqD4AjP9GxH3hoMfxER5JvAI8Dn0gynWTTuMe0wK4F/oDZvySfa6+bxj2oBXYJ8FiS55n9I2hvVS2KqZ2LzMXAD5L8CHgKeKSqvrtQH7ZoprJKkka3aK4cJEmjMxwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSZ3/B04WBkpY5INVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6879ce8cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_jokes = []\n",
    "for i in range(len(reddit_jokes)):\n",
    "    r_joke = reddit_jokes[i]\n",
    "    #|print(r_joke)\n",
    "    r_joke['rating']=round(math.log(r_joke['score']+random.randrange(1,10))/math.log(10)*5/2, 2)\n",
    "    if r_joke['rating']>5:\n",
    "        r_joke['rating']=5\n",
    "    del r_joke['score'] \n",
    "    r_joke['body'] = r_joke['title']+\" \"+r_joke['body']\n",
    "    del r_joke['title']\n",
    "for s_joke in stupid_jokes:\n",
    "    del s_joke['category']\n",
    "\n",
    "combined = [joke['rating'] for joke in reddit_jokes]\n",
    "combined = combined + [joke['rating'] for joke in stupid_jokes]\n",
    "plt.hist(combined,bins=5);\n",
    "\n",
    "combined_jokes = reddit_jokes + stupid_jokes\n",
    "\n",
    "title_body = [joke['body']+' ' for joke in combined_jokes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "for joke in title_body:\n",
    "    text = text + ' ' + joke + ' ' + EOJ + ' '\n",
    "    if len(text) > 800000: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls ‚ÄòJesus Christ, are you still in there?'‚Äù  xeoj  You hear about the University book store worker w\n"
     ]
    }
   ],
   "source": [
    "len(text)\n",
    "print(text[1000:1100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 125\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\x00', '\\n', '\\r', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~', '\\x9d', '\\xa0', '¬¢', '¬£', '¬∞', '¬¥', '√®', '√©', '√±', '√≥', 'Œº', 'œÄ', '‚Äì', '‚Äî', '‚Äò', '‚Äô', '‚Äú', '‚Äù', '‚Ä¢', '‚Ä¶', '\\u2028', '‚Ç¨', '‚àö', '‚à´', '\\ufeff', 'üá©', 'üá∞', 'üòÇ', 'üò®', 'ü§£']\n"
     ]
    }
   ],
   "source": [
    "chars.insert(0, \"\\0\")\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears there are Emojis in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = {c: i for i, c in enumerate(chars)}\n",
    "indices_char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 44, 3, 75, 68, 87, 72, 3, 75, 82]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [char_indices[c] for c in text]\n",
    "\n",
    "idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I hate how you cant even say black paint anymore Now I have to say \"L'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emojis in Jokes\n",
    "\n",
    "How many of them have them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "emojis = chars[-3:]\n",
    "\n",
    "def containsEmoji(joke):\n",
    "    for emoji in emojis:\n",
    "        if emoji in joke:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "#type(title_body[0])\n",
    "contains_emoji = [joke for joke in title_body if containsEmoji(joke)]\n",
    "print(len(contains_emoji))\n",
    "# contains_emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So not that many. \n",
    "Interestingly though, there seems to be more emojis than we found initially. \n",
    "\n",
    "## Three character model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800048"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = 3\n",
    "c1_data = c2_data = c3_data = c4_data = []\n",
    "for i in range(0, len(idx)-cs, cs):\n",
    "    c1_data.append(idx[i])\n",
    "    c2_data.append(idx[i+1])\n",
    "    c3_data.append(idx[i+2])\n",
    "    c4_data.append(idx[i+3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the input and outputs of our RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.stack(c1_data)\n",
    "x2 = np.stack(c2_data)\n",
    "x3 = np.stack(c3_data)\n",
    "y  = np.stack(c4_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 256\n",
    "embeddings_sz = 42 # size of embeddings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These libraries require some setup, try the pip install git+https.github.com/... trick\n",
    "from fastai.io import *\n",
    "from fastai.conv_learner import *\n",
    "\n",
    "from fastai.column_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeCharRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.l_in = nn.Linear(embeddings_sz, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, c1, c2, c3):\n",
    "        in1 = F.relu(self.l_in(self.e(c1))) # Why relu?\n",
    "        in2 = F.relu(self.l_in(self.e(c2)))\n",
    "        in3 = F.relu(self.l_in(self.e(c3)))\n",
    "        \n",
    "        h = V(torch.zeros(in1.size()).cuda())\n",
    "        h = F.tanh(self.l_hidden(h+in1))\n",
    "        h = F.tanh(self.l_hidden(h+in2))\n",
    "        h = F.tanh(self.l_hidden(h+in3))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', [-1], np.stack([x1,x2,x3], axis=1), y, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ThreeCharRNN(vocab_size, embeddings_sz).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = iter(md.trn_dl)\n",
    "*xs,yt = next(train_iterator)\n",
    "t = model(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52f8607e0a9442ca68aa3cd6d8d6f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      0.002085   0.000111  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00011062622]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, md, epochs=1, opt=optimizer, crit=F.nll_loss) # The negative log likelihood loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(input):\n",
    "   running_indicies = []\n",
    "   indicies = []\n",
    "   for char in input:\n",
    "       running_indicies.append(char_indices[char])\n",
    "   for i in range(10):\n",
    "       indicies = np.array(running_indicies[-3:])\n",
    "       indicies = T(indicies)\n",
    "       prediction = model(*VV(indicies))\n",
    "       pred_idx = np.argmax(to_np(prediction))\n",
    "       running_indicies.append(pred_idx)\n",
    "   result_chars = []\n",
    "   for index in running_indicies:\n",
    "       result_chars.append(chars[index])\n",
    "   return result_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y', '.', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('y. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'l', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o', 'o']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('blo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\x00', '\\n', '\\r', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~', '\\x9d', '\\xa0', '¬¢', '¬£', '¬∞', '¬¥', '√®', '√©', '√±', '√≥', 'Œº', 'œÄ', '‚Äì', '‚Äî', '‚Äò', '‚Äô', '‚Äú', '‚Äù', '‚Ä¢', '‚Ä¶', '\\u2028', '‚Ç¨', '‚àö', '‚à´', '\\ufeff', 'üá©', 'üá∞', 'üòÇ', 'üò®', 'ü§£']\n"
     ]
    }
   ],
   "source": [
    "print(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a bigger RNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_len=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_in_jokes = [[idx[i+j] for i in range(rnn_len)] for j in range(len(idx)-rnn_len)]\n",
    "\n",
    "char_input = []\n",
    "for j in range(len(idx)-rnn_len):\n",
    "    tmp = []\n",
    "    for i in range(rnn_len):\n",
    "        tmp.append(idx[i+j])\n",
    "    char_input.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_output = []\n",
    "for j in range(len(idx)-rnn_len):\n",
    "    char_output.append(idx[j+rnn_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.stack(char_input, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800040, 8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800040,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.stack(char_output)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, 44,  3, 75, 68, 87, 72,  3],\n",
       "       [44,  3, 75, 68, 87, 72,  3, 75],\n",
       "       [ 3, 75, 68, 87, 72,  3, 75, 82],\n",
       "       [75, 68, 87, 72,  3, 75, 82, 90],\n",
       "       [68, 87, 72,  3, 75, 82, 90,  3],\n",
       "       [87, 72,  3, 75, 82, 90,  3, 92],\n",
       "       [72,  3, 75, 82, 90,  3, 92, 82],\n",
       "       [ 3, 75, 82, 90,  3, 92, 82, 88]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:rnn_len,:rnn_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y[:rnn_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(idx)-rnn_len-1)\n",
    "# val_idx.shape\n",
    "model_data = ColumnarModelData.from_arrays('.', val_idx, xs, y, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLoopModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.l_in = nn.Linear(embeddings_sz, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *rnn_len):\n",
    "#         pdb.set_trace()\n",
    "        bs = rnn_len[0].size(0)\n",
    "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
    "        for c in rnn_len:\n",
    "            inp = F.relu(self.l_in(self.e(c)))\n",
    "            h = F.tanh(self.l_hidden(h+inp))\n",
    "            \n",
    "        return F.log_softmax(self.l_out(h), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharLoopModel(vocab_size, embeddings_sz).cuda()\n",
    "opt = optim.Adam(model.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66cb43ba9f0047b7adfdbb19d06e2a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      2.050437   2.05508   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.05508]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, epochs=1, opt=opt, crit=F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d17dccb02f4664a66abd9bbd05c433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.79886    1.800415  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8004147]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, epochs=1, opt=opt, crit=F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = model(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' a blond')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('into a b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'into a be the said the said the said the said th'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_n('into a b', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLoopConcatModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.l_in = nn.Linear(embeddings_sz+n_hidden, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *rnn_len):\n",
    "        bs = rnn_len[0].size(0)\n",
    "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
    "        for c in rnn_len:\n",
    "            inp = torch.cat((h, self.e(c)), 1)\n",
    "            inp = F.relu(self.l_in(inp))\n",
    "            h = F.tanh(self.l_hidden(inp))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharLoopConcatModel(vocab_size, embeddings_sz).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)\n",
    "t = m(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c510db90a54fc18621e79e6e0509fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      0.000262   0.000197  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00019741058]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6354fc27084ef69a00c23bc436a910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      0.000452   0.000144  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00014400482]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'üá∞'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with Multiple Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.rnn = nn.RNN(embeddings_sz, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *rnn_len):\n",
    "        bs = rnn_len[0].size(0)\n",
    "        h = V(torch.zeros(1, bs, n_hidden))\n",
    "        inp = self.e(torch.stack(rnn_len))\n",
    "        outp,h = self.rnn(inp, h)\n",
    "        \n",
    "        return F.log_softmax(self.l_out(outp[-1]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharRnn(vocab_size, embeddings_sz).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 42])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m.e(V(torch.stack(xs)))\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 512, 256]), torch.Size([1, 512, 256]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht = V(torch.zeros(1, 512,n_hidden))\n",
    "outp, hn = m.rnn(t, ht)\n",
    "outp.size(), hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 125])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m(*V(xs)); t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c1a1346fc747f4adae3c5bee010016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      0.000201   0.00025   \n",
      "    1      0.000305   0.000109                                    \n",
      "    2      1.2e-05    2.5e-05                                     \n",
      "    3      2e-06      4e-06                                       \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.8146973e-06]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699dc8d9783d44ec9a36d14be14510ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      1e-06      2e-06     \n",
      "    1      1e-06      2e-06                                       \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9073486e-06]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 2, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for thos/// /////// /////// /////// /////// ////'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_n('for thos', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_in_dat = [[idx[i+j] for i in range(rnn_len)] for j in range(0, len(idx)-rnn_len-1, rnn_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_out_dat = [[idx[i+j] for i in range(rnn_len)] for j in range(1, len(idx)-rnn_len, rnn_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100005, 8)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = np.stack(c_in_dat)\n",
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, 44,  3, 75, 68, 87, 72,  3],\n",
       "       [75, 82, 90,  3, 92, 82, 88,  3],\n",
       "       [70, 68, 81, 87,  3, 72, 89, 72],\n",
       "       [81,  3, 86, 68, 92,  3, 69, 79],\n",
       "       [68, 70, 78,  3, 83, 68, 76, 81],\n",
       "       [87,  3, 68, 81, 92, 80, 82, 85],\n",
       "       [72,  3, 49, 82, 90,  3, 44,  3],\n",
       "       [75, 68, 89, 72,  3, 87, 82,  3]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:rnn_len,:rnn_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100005, 8)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = np.stack(c_out_dat)\n",
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44,  3, 75, 68, 87, 72,  3, 75],\n",
       "       [82, 90,  3, 92, 82, 88,  3, 70],\n",
       "       [68, 81, 87,  3, 72, 89, 72, 81],\n",
       "       [ 3, 86, 68, 92,  3, 69, 79, 68],\n",
       "       [70, 78,  3, 83, 68, 76, 81, 87],\n",
       "       [ 3, 68, 81, 92, 80, 82, 85, 72],\n",
       "       [ 3, 49, 82, 90,  3, 44,  3, 75],\n",
       "       [68, 89, 72,  3, 87, 82,  3, 86]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[:rnn_len,:rnn_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(xs)-rnn_len-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', val_idx, xs, ys, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.rnn = nn.RNN(embeddings_sz, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *rnn_len):\n",
    "        bs = rnn_len[0].size(0)\n",
    "        h = V(torch.zeros(1, bs, n_hidden))\n",
    "        inp = self.e(torch.stack(rnn_len))\n",
    "        outp,h = self.rnn(inp, h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqRnn(vocab_size, embeddings_sz).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)\n",
    "t = m(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2e392bcac4462798ec6f41ecc6f047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/157 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2 or 4 dimensions (got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-8e1cb7e8a6e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/notebooks/funnynet/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, epochs, opt, crit, metrics, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/funnynet/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxtra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected 2 or 4 dimensions (got {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2 or 4 dimensions (got 3)"
     ]
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_next('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_next('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "Now we will try an LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import vocab, data\n",
    "\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "from fastai import sgdr\n",
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(xs)-rnn_len-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', val_idx, xs, ys, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz, bs, nl):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.nl = vocab_size,nl\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.rnn = nn.LSTM(embeddings_sz, n_hidden, nl, dropout=0.5)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, rnn_len):\n",
    "        bs = rnn_len[0].size(0)\n",
    "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(rnn_len), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.h = (V(torch.zeros(self.nl, bs, n_hidden)),\n",
    "                  V(torch.zeros(self.nl, bs, n_hidden)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulLSTM(md.nt, embeddings_sz, 512, 2).cuda()\n",
    "#lo = LayerOptimizer(optim.Adam, m, 1e-2, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{PATH}models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit(m, md, 2, lo.opt, F.nll_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
