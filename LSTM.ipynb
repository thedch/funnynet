{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funnynet\n",
    "\n",
    "## A neural network that makes jokes\n",
    "\n",
    "Special thanks to taivop for providing the [dataset](https://github.com/taivop/joke-dataset).\n",
    "\n",
    "This notebook is heavily inspired by [fastai NLP work](https://github.com/fastai/fastai/blob/master/courses/dl2/imdb.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "EOJ = 'xeoj'  # end of joke tag\n",
    "\n",
    "PATH=Path('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('data/val'), PosixPath('data/.ipynb_checkpoints'), PosixPath('data/trn'), PosixPath('data/stupidstuff.json'), PosixPath('data/models'), PosixPath('data/reddit_jokes.json')]\n"
     ]
    }
   ],
   "source": [
    "files = list(PATH.iterdir())\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in files:\n",
    "    if \"eddit\" in str(fname):\n",
    "        reddit_dataset = str(fname)\n",
    "    if \"upid\" in str(fname):\n",
    "        stupid_dataset = str(fname)\n",
    "reddit_jokes = json.load(open(reddit_dataset))\n",
    "stupid_jokes = json.load(open(stupid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194553"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reddit_jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'body': 'Now I have to say \"Leroy can you please paint the fence?\"',\n",
       " 'id': '5tz52q',\n",
       " 'score': 1,\n",
       " 'title': 'I hate how you cant even say black paint anymore'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_jokes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's discard all the jokes that have 0 score, as they aren't that helpful for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rated_jokes = [joke for joke in reddit_jokes if joke['score'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132992"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rated_jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172.94791416025024, 48526)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = [joke['score'] for joke in rated_jokes]\n",
    "np.mean(scores),np.max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fccb30e7160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "low_scores = [score for score in scores]\n",
    "plt.xscale('log', nonposx='clip')\n",
    "plt.ylim(ymax=200000)\n",
    "#plt.axes.set_ylim([0,200000])\n",
    "plt.hist(low_scores, bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I hate how you cant even say black paint anymore Now I have to say \"Leroy can you please paint the fence?\"'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_body = [joke['title']+' '+joke['body'] for joke in rated_jokes]\n",
    "title_body[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horrible, but formatted correctly. Now, let's combine all the jokes into one long string, using the `EOJ` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fccb73e6dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_jokes = []\n",
    "for i in range(len(reddit_jokes)):\n",
    "    r_joke = reddit_jokes[i]\n",
    "    r_joke['rating']=round(math.log(r_joke['score']+random.randrange(1,10))/math.log(10)*5/2, 2)\n",
    "    if r_joke['rating']>5: # TODO: use max() here\n",
    "        r_joke['rating']=5\n",
    "    del r_joke['score'] \n",
    "    r_joke['body'] = r_joke['title']+\" \"+r_joke['body']\n",
    "    del r_joke['title']\n",
    "for s_joke in stupid_jokes:\n",
    "    del s_joke['category']\n",
    "\n",
    "combined = [joke['rating'] for joke in reddit_jokes]\n",
    "combined = combined + [joke['rating'] for joke in stupid_jokes]\n",
    "plt.hist(combined,bins=5);\n",
    "\n",
    "combined_jokes = reddit_jokes + stupid_jokes\n",
    "\n",
    "title_body = [joke['body']+' ' for joke in combined_jokes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "for joke in title_body:\n",
    "    text = text + ' ' + joke + ' ' + EOJ + ' '\n",
    "    if len(text) > 800000: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls ‚ÄòJesus Christ, are you still in there?'‚Äù  xeoj  You hear about the University book store worker w\n"
     ]
    }
   ],
   "source": [
    "len(text)\n",
    "print(text[1000:1100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 125\n",
      "['\\x00', '\\n', '\\r', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~', '\\x9d', '\\xa0', '¬¢', '¬£', '¬∞', '¬¥', '√®', '√©', '√±', '√≥', 'Œº', 'œÄ', '‚Äì', '‚Äî', '‚Äò', '‚Äô', '‚Äú', '‚Äù', '‚Ä¢', '‚Ä¶', '\\u2028', '‚Ç¨', '‚àö', '‚à´', '\\ufeff', 'üá©', 'üá∞', 'üòÇ', 'üò®', 'ü§£']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)\n",
    "chars.insert(0, \"\\0\")\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears there are Emojis in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = {c: i for i, c in enumerate(chars)}\n",
    "indices_char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 44, 3, 75, 68, 87, 72, 3, 75, 82]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [char_indices[c] for c in text]\n",
    "\n",
    "idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I hate how you cant even say black paint anymore Now I have to say \"L'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partitioning the dataset and writing it to /data/trn/trn.txt and /data/val/val.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mmodels\u001b[0m/  reddit_jokes.json  stupidstuff.json  \u001b[01;34mtrn\u001b[0m/  \u001b[01;34mval\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "PATH='data/'\n",
    "\n",
    "TRN_PATH = 'trn/'\n",
    "VAL_PATH = 'val/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "%ls {PATH} # Don't do this, use pathlib(), it's a lot cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = open(TRN+\"trn.txt\",\"wb\")\n",
    "#rn.write(\"test\")\n",
    "trn.write(text[0:int(len(text)*2/3)].encode('utf-8'))#str(idx[0:int(len(idx)*2/3)]))\n",
    "trn.close()\n",
    "val = open(VAL+\"val.txt\",\"wb\")\n",
    "#al.write(\"test\")\n",
    "val.write(text[int(len(text)*2/3):len(text)-1].encode('utf-8'))#str(idx[int(len(idx)*2/3):len(idx)-1]))\n",
    "val.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three character model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800048"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = 3\n",
    "c1_data = c2_data = c3_data = c4_data = []\n",
    "for i in range(0, len(idx)-cs, cs):\n",
    "    c1_data.append(idx[i])\n",
    "    c2_data.append(idx[i+1])\n",
    "    c3_data.append(idx[i+2])\n",
    "    c4_data.append(idx[i+3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the input and outputs of our RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.stack(c1_data)\n",
    "x2 = np.stack(c2_data)\n",
    "x3 = np.stack(c3_data)\n",
    "y  = np.stack(c4_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 256\n",
    "embeddings_sz = 42 #size of embeddings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These libraries require some setup, try the pip install git+https.github.com/... trick\n",
    "from fastai.io import *\n",
    "from fastai.conv_learner import *\n",
    "\n",
    "from fastai.column_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeCharRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.l_in = nn.Linear(embeddings_sz, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, c1, c2, c3):\n",
    "        in1 = F.relu(self.l_in(self.e(c1))) # Why relu?\n",
    "        in2 = F.relu(self.l_in(self.e(c2)))\n",
    "        in3 = F.relu(self.l_in(self.e(c3)))\n",
    "        \n",
    "        h = V(torch.zeros(in1.size()).cuda())\n",
    "        h = F.tanh(self.l_hidden(h+in1))\n",
    "        h = F.tanh(self.l_hidden(h+in2))\n",
    "        h = F.tanh(self.l_hidden(h+in3))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', [-1], np.stack([x1,x2,x3], axis=1), y, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ThreeCharRNN(vocab_size, embeddings_sz).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = iter(md.trn_dl)\n",
    "*xs,yt = next(train_iterator)\n",
    "t = model(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a12a937b7634b6481e44493a94869a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      0.003076   2.7e-05   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.670288e-05]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, md, epochs=1, opt=optimizer, crit=F.nll_loss) # The negative log likelihood loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(optimizer, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d983778e9c734acf89a7fd94588ba18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      3.5e-05    6e-06     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.722046e-06]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, md, 1, optimizer, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: what is going on with the indentation here? Use 4 spaces, not 3\n",
    "\n",
    "# def get_next(input):\n",
    "#     running_indicies = [] # Use get_next_n() here\n",
    "#     indicies = []\n",
    "#     for char in input:\n",
    "#         running_indicies.append(char_indices[char])\n",
    "#     for i in range(10):\n",
    "#         indicies = np.array(running_indicies[-3:])\n",
    "#         indicies = T(indicies)\n",
    "#        prediction = model(*VV(indicies))\n",
    "#        pred_idx = np.argmax(to_np(prediction))\n",
    "#        running_indicies.append(pred_idx)\n",
    "#    result_chars = []\n",
    "#    for index in running_indicies:\n",
    "#        result_chars.append(chars[index])\n",
    "#    return result_chars\n",
    "\n",
    "\n",
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = model(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('y. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('blo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a bigger RNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_len=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_in_jokes = [[idx[i+j] for i in range(rnn_len)] for j in range(len(idx)-rnn_len)]\n",
    "# The above line and the below for loops are the same, just refactored to be easier to read\n",
    "\n",
    "char_input = []\n",
    "for j in range(len(idx)-rnn_len):\n",
    "    tmp = []\n",
    "    for i in range(rnn_len):\n",
    "        tmp.append(idx[i+j])\n",
    "    char_input.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_output = []\n",
    "for j in range(len(idx)-rnn_len):\n",
    "    char_output.append(idx[j+rnn_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.stack(char_input, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800040, 8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800040,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.stack(char_output)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, 44,  3, 75, 68, 87, 72,  3],\n",
       "       [44,  3, 75, 68, 87, 72,  3, 75],\n",
       "       [ 3, 75, 68, 87, 72,  3, 75, 82],\n",
       "       [75, 68, 87, 72,  3, 75, 82, 90],\n",
       "       [68, 87, 72,  3, 75, 82, 90,  3],\n",
       "       [87, 72,  3, 75, 82, 90,  3, 92],\n",
       "       [72,  3, 75, 82, 90,  3, 92, 82],\n",
       "       [ 3, 75, 82, 90,  3, 92, 82, 88]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:rnn_len,:rnn_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y[:rnn_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(idx)-rnn_len-1)\n",
    "# val_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = ColumnarModelData.from_arrays('.', val_idx, xs, y, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLoopModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.l_in = nn.Linear(embeddings_sz, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *rnn_len):\n",
    "#         pdb.set_trace()\n",
    "        bs = rnn_len[0].size(0)\n",
    "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
    "        for c in rnn_len:\n",
    "            inp = F.relu(self.l_in(self.e(c)))\n",
    "            h = F.tanh(self.l_hidden(h+inp))\n",
    "            \n",
    "        return F.log_softmax(self.l_out(h), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharLoopModel(vocab_size, embeddings_sz).cuda()\n",
    "opt = optim.Adam(model.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c968600ff5a843b08dc5af6c1777fb0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      2.033698   2.071263  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.071263]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, epochs=1, opt=opt, crit=F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9986c65bf6d483eab004ef8e35191c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.767279   1.77659   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7765901]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, epochs=1, opt=opt, crit=F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' a blond')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('into a b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'into a been the man a been the man a been the ma'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_n('into a b', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLoopConcatModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.l_in = nn.Linear(embeddings_sz+n_hidden, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *rnn_len):\n",
    "        bs = rnn_len[0].size(0)\n",
    "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
    "        for c in rnn_len:\n",
    "            inp = torch.cat((h, self.e(c)), 1)\n",
    "            inp = F.relu(self.l_in(inp))\n",
    "            h = F.tanh(self.l_hidden(inp))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharLoopConcatModel(vocab_size, embeddings_sz).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)\n",
    "t = m(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64946f6ed8f24830945a07a6cc0d8730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      0.000316   0.000222  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00022220612]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e62a5ec522847539ba67ccb0c424bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      0.000107   0.000166  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00016593933]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('wome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('beca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('char')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN with pytorch\n",
    "\n",
    "### Model with Multiple Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.rnn = nn.RNN(embeddings_sz, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *rnn_len):\n",
    "        #print(\"rnn_len: \"+str(rnn_len))\n",
    "        bs = rnn_len[0].size(0)\n",
    "        h = V(torch.zeros(1, bs, n_hidden))\n",
    "        inp = self.e(torch.stack(rnn_len))\n",
    "        outp,h = self.rnn(inp, h)\n",
    "        \n",
    "        return F.log_softmax(self.l_out(outp[-1]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharRnn(vocab_size, embeddings_sz).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 42])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m.e(V(torch.stack(xs)))\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 512, 256]), torch.Size([1, 512, 256]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht = V(torch.zeros(1, 512,n_hidden))\n",
    "outp, hn = m.rnn(t, ht)\n",
    "outp.size(), hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 125])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m(*V(xs)); t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514f3078882240858a4e1ad0c4ebcf10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      0.000156   0.000163  \n",
      "    1      2.9e-05    3.4e-05                                     \n",
      "    2      1e-05      1.1e-05                                     \n",
      "    3      3e-06      4e-06                                       \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.8146973e-06]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20f610b7bdd404fb458123dc98735aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      1e-06      2e-06     \n",
      "    1      1e-06      2e-06                                       \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9073486e-06]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 2, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for thosfor t&os or t                           '"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_n('for thos', 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi output model\n",
    "\n",
    "### Setup\n",
    "\n",
    "Let's take non-overallping sets of characters this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_in_dat = [[idx[i+j] for i in range(rnn_len)] for j in range(0, len(idx)-rnn_len-1, rnn_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_out_dat = [[idx[i+j] for i in range(rnn_len)] for j in range(1, len(idx)-rnn_len, rnn_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100005, 8)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = np.stack(c_in_dat)\n",
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, 44,  3, 75, 68, 87, 72,  3],\n",
       "       [75, 82, 90,  3, 92, 82, 88,  3],\n",
       "       [70, 68, 81, 87,  3, 72, 89, 72],\n",
       "       [81,  3, 86, 68, 92,  3, 69, 79],\n",
       "       [68, 70, 78,  3, 83, 68, 76, 81],\n",
       "       [87,  3, 68, 81, 92, 80, 82, 85],\n",
       "       [72,  3, 49, 82, 90,  3, 44,  3],\n",
       "       [75, 68, 89, 72,  3, 87, 82,  3]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:rnn_len,:rnn_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100005, 8)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = np.stack(c_out_dat)\n",
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44,  3, 75, 68, 87, 72,  3, 75],\n",
       "       [82, 90,  3, 92, 82, 88,  3, 70],\n",
       "       [68, 81, 87,  3, 72, 89, 72, 81],\n",
       "       [ 3, 86, 68, 92,  3, 69, 79, 68],\n",
       "       [70, 78,  3, 83, 68, 76, 81, 87],\n",
       "       [ 3, 68, 81, 92, 80, 82, 85, 72],\n",
       "       [ 3, 49, 82, 90,  3, 44,  3, 75],\n",
       "       [68, 89, 72,  3, 87, 82,  3, 86]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[:rnn_len,:rnn_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(xs)-rnn_len-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', val_idx, xs, ys, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.rnn = nn.RNN(embeddings_sz, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *rnn_len):\n",
    "        bs = rnn_len[0].size(0)\n",
    "        h = V(torch.zeros(1, bs, n_hidden))\n",
    "        inp = self.e(torch.stack(rnn_len))\n",
    "        outp,h = self.rnn(inp, h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqRnn(vocab_size, embeddings_sz).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xst,yt = next(it)\n",
    "#t = m(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_loss_seq(inp, targ):\n",
    "    sl,bs,nh = inp.size()\n",
    "    targ = targ.transpose(0,1).contiguous().view(-1)\n",
    "    return F.nll_loss(inp.view(-1,nh), targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4bb380024e46c69983d432b4a8bc42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      2.512579   2.36354   \n",
      "    1      2.215545   2.170297                              \n",
      "    2      2.095591   2.077355                              \n",
      "    3      2.022197   2.016496                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.016496]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095e0144bd094eebafcc5d510314adc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.983031   2.004195  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.0041955]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity init!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqRnn(vocab_size, embeddings_sz).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    1     0     0  ...      0     0     0\n",
       "    0     1     0  ...      0     0     0\n",
       "    0     0     1  ...      0     0     0\n",
       "       ...          ‚ã±          ...       \n",
       "    0     0     0  ...      1     0     0\n",
       "    0     0     0  ...      0     1     0\n",
       "    0     0     0  ...      0     0     1\n",
       "[torch.cuda.FloatTensor of size 256x256 (GPU 0)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.rnn.weight_hh_l0.data.copy_(torch.eye(n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e32f9c690b4d3d9edf25443a26761c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      2.260107   2.156497  \n",
      "    1      2.055424   2.046262                              \n",
      "    2      1.983271   1.99363                               \n",
      "    3      1.939081   1.963729                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9637289]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c22dadfac734af790d57a22a9891e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.854605   1.887773  \n",
      "    1      1.846932   1.881565                              \n",
      "    2      1.839614   1.875512                              \n",
      "    3      1.829479   1.87121                               \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8712099]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful model\n",
    "\n",
    "### Adding State: RNN\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import vocab, data\n",
    "\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mmodels\u001b[0m/  reddit_jokes.json  stupidstuff.json  \u001b[01;34mtrn\u001b[0m/  \u001b[01;34mval\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "PATH='data/'\n",
    "\n",
    "TRN_PATH = 'trn/'\n",
    "VAL_PATH = 'val/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like this next part assumes we have already partitioned the data into trn/trn.txt and val/val.txt for training and validation sets, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: <torchtext.data.field.Field object at 0x7fcbf5a6dac8>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1030, 80, 1, 528056)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=list)\n",
    "print(\"TEXT: \"+str(TEXT))\n",
    "bs=64; bptt=8; n_fac=42; n_hidden=256\n",
    "\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
    "\n",
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs):\n",
    "        self.vocab_size = vocab_size\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulRnn(md.nt, n_fac, 512).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705e16255a71420c87b46240f525ff69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.860277   1.866542  \n",
      "    1      1.699016   1.744627                                \n",
      "    2      1.619228   1.685334                                \n",
      "    3      1.570107   1.6544                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6544005]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd37224b57c4a4381d0f8e9376f5b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.494319   1.613584  \n",
      "    1      1.49585    1.607414                                \n",
      "    2      1.492609   1.603698                                \n",
      "    3      1.488074   1.600259                                \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6002587]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_lrs(opt, 1e-4)\n",
    "\n",
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "Now we will try an LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import vocab, data\n",
    "\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "from fastai import sgdr\n",
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_idx = get_cv_idxs(len(xs)-rnn_len-1)\n",
    "# print(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(xs)\n",
    "# print(ys)\n",
    "# md = ColumnarModelData.from_arrays('.', val_idx, xs, ys, bs=512)\n",
    "# print(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz, bs, nl):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.nl = vocab_size,nl\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.rnn = nn.LSTM(embeddings_sz, n_hidden, nl, dropout=0.5)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, rnn_len):\n",
    "        bs = rnn_len[0].size(0)\n",
    "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(rnn_len), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.h = (V(torch.zeros(self.nl, bs, n_hidden)),\n",
    "                  V(torch.zeros(self.nl, bs, n_hidden)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulLSTM(len(chars)+1,embeddings_sz, 512, 2).cuda()\n",
    "lo = LayerOptimizer(optim.Adam, m, 1e-2, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{PATH}models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11951dcfc1241c08a8e950aa8192674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.780312   1.753159  \n",
      "    1      1.709716   1.686558                                \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6865584]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 2, lo.opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## He trains for 2^6 epochs... I'm not waiting that long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d191414de1f940e0aad42286a9eccc3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.572894   1.558888  \n",
      "    1      1.598092   1.5811                                  \n",
      "    2      1.490808   1.504915                                 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5049154]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 2**2-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9694dc096f484e95ac63d63eb90afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.482831   1.50152   \n",
      "    1      1.483222   1.498058                                \n",
      "    2      1.476619   1.497165                                 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4971647]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 2**2-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = TEXT.numericalize(inp)\n",
    "    #print(idxs)\n",
    "    p = m(VV(idxs.transpose(0,1)))\n",
    "    #print(p)\n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    #print(int(r))\n",
    "    #print(chars[int(r)])\n",
    "    return TEXT.vocab.itos[to_np(r)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('into a b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('a ma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('blon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "into a book?.you had a bus it's slow.  xeoj  if he reddenisebraps you call my lost spanet turn, and is downly out some a regrateed paid. the brugin. then huts, the dorn to the local.they is medain.  xeoj  why did you was a hot eats that manhea, works of co. he takes. to having the worlds timed on his dog condors fire with the koom your mach johnder shair and, 'counted him trumple.\"the no cot sure legs the\n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('into a b', 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blonds, but, the back fuck. he would stuff.\" \"so the felle? i used her lading have is says when hour, the was thes up.  xeoj   xeoj  xeoj  xeoj a placeler jees. then you die. it to being too diad. they: \"okay fucks. mustred... what they? my precticed has on my befoney. what my cleamate. booked and is kissed in um.  xeoj  xeoj  xeoj  xeoj  xeoj  xeoj  xeoj sist can grationate 40 in thing in for upping \n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('blon', 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what do you do mornhop a hive give most in 92.into the mat, the boy-tautely he reich to the high he's lawyer this meams ripses and the man she saad? you went the woman? i waged stammy time by a triphoppli back purnously beaation happens he's not that his calls ad joki?\"  xeoj  p)the day araze, he went the musets! and just with a dick and he never ever? i an explain it is now a sate.., haw moation of the ti\n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('what do y',400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n_jokes(prompt,n):\n",
    "    jokes = []\n",
    "    c = ''\n",
    "    for j in range(n):\n",
    "        inp = prompt\n",
    "        res = prompt\n",
    "        while res[-5:-1]!=\"xeoj\":\n",
    "            c = get_next(inp)\n",
    "            res += c\n",
    "            inp = inp[1:]+c\n",
    "        jokes.append(res)\n",
    "    return jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the blonde.   xeoj \n",
      "\n",
      "\n",
      "the blonde. so swit go to no beast?\"  xeoj \n",
      "\n",
      "\n",
      "the blonde a jewns to same glang. he sading to dinner.\" \"honey, with dip me having and the declives making ital! oh only next to terved a rose a shop.final gets on the driver.‚Äùwe doesn't hours\" i'm have sex philes. a prostously i'm seen\" just believe time he's heaving been pustment, the mean.   xeoj \n",
      "\n",
      "\n",
      "the blonde cluck! i call three. we're down ducks drunk is a lawder sits his wall and knock is ‚Äôalman punch.  xeoj \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for joke in get_next_n_jokes('the blon',4):\n",
    "    print(joke)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he smashes the birth and my exice is orighter is going away commorist when i prebles and buy who's just couldn't keeper go for legs...stears in this first bartender said, ‚Äúnoed some god.....and buys my mushing. sorry the hooded up and asked the condict*\"she don't it so cloves today the beer food the gartendal bifts into the bartuny 4 move that i died in the doctor, the crustrapate was juy light parked been ablady: \"no into a all you.\"!!\".the ogires asks her terrute slap there shanks. they've gently shight up a pizzachpultan.  xeoj \n",
      "\n",
      "\n",
      "he smashes the bire far chonopes out of missurianisubon he puts with the second andrairing are class. and long and says \"childed him began after you call she father suckic fisand, and air, he'd a little into expanss of my has and she didn't you chips lating?\"  xeoj \n",
      "\n",
      "\n",
      "he smashes the bird he can't have attanded moins in near of there this asks, \"i'll atchen?\" the tocking the poke over him in a fair.  xeoj \n",
      "\n",
      "\n",
      "he smashes the birch. his blonde, thought jethers knows going the bars of your man says, \"ok, for impression and snake, but then, 95' may duck by him in a gan cows his cital not minutes an 180$0 ims sold opening iisters? i have studenting of hihs was aat sex him.\" says: \"welcome in the ruce stands incating in live up, doctor, my girlfriend laugh  xeoj \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for joke in get_next_n_jokes('he smashes the bir',4):\n",
    "    print(joke)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
