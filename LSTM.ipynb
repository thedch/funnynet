{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funnynet\n",
    "\n",
    "## A neural network that makes jokes\n",
    "\n",
    "Special thanks to taivop for providing the [dataset](https://github.com/taivop/joke-dataset).\n",
    "\n",
    "This notebook is heavily inspired by [fastai NLP work](https://github.com/fastai/fastai/blob/master/courses/dl2/imdb.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "EOJ = 'xeoj'  # end of joke tag\n",
    "\n",
    "PATH=Path('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('data/models'), PosixPath('data/reddit_jokes.json'), PosixPath('data/val'), PosixPath('data/stupidstuff.json'), PosixPath('data/trn')]\n"
     ]
    }
   ],
   "source": [
    "files = list(PATH.iterdir())\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/stupidstuff.json'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stupid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in files:\n",
    "    if \"reddit_jokes.json\" in str(fname):\n",
    "        reddit_dataset = str(fname)\n",
    "    if \"stupidstuff.json\" in str(fname):\n",
    "        stupid_dataset = str(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_jokes = json.load(open(reddit_dataset))\n",
    "stupid_jokes = json.load(open(stupid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194553"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reddit_jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'body': 'Now I have to say \"Leroy can you please paint the fence?\"',\n",
       " 'id': '5tz52q',\n",
       " 'score': 1,\n",
       " 'title': 'I hate how you cant even say black paint anymore'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_jokes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's discard all the jokes that have 0 score, as they aren't that helpful for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rated_jokes = [joke for joke in reddit_jokes if joke['score'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132992"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rated_jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I hate how you cant even say black paint anymore Now I have to say \"Leroy can you please paint the fence?\"'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_plus_body = [joke['title'] + ' ' + joke['body'] for joke in rated_jokes]\n",
    "title_plus_body[0]\n",
    "# len(title_plus_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horrible, but formatted correctly. Now, let's combine all the jokes into one long string, using the `EOJ` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_chars = \"!\\\"\\'“”‘’(),$*-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz \\n\"\n",
    "# print(accepted_chars)\n",
    "\n",
    "text = ''\n",
    "for joke in title_plus_body:\n",
    "    for char in joke:\n",
    "        if char not in accepted_chars:\n",
    "            break\n",
    "    else:\n",
    "        text += ' ' + joke + ' ' + EOJ + ' '\n",
    "    if len(text) > 2E6:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit me, not that they were going to destroy the housing market 20 years later. xeoj  My boss said to\n"
     ]
    }
   ],
   "source": [
    "len(text)\n",
    "print(text[1000:1100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 86\n",
      "['\\x00', '\\n', ' ', '!', '\"', '$', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '‘', '’', '“', '”']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)\n",
    "chars.insert(0, \"\\0\")\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = {c: i for i, c in enumerate(chars)}\n",
    "indices_char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 35, 2, 63, 56, 75, 60, 2, 63, 70]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [char_indices[c] for c in text]\n",
    "\n",
    "idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I hate how you cant even say black paint anymore Now I have to say \"L'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup, creating .txt files to train LSTM on\n",
    "\n",
    "Partitioning the dataset and writing it to /data/trn/trn.txt and /data/val/val.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "(PATH/'val').mkdir(exist_ok=True)\n",
    "(PATH/'trn').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/models'),\n",
       " PosixPath('data/reddit_jokes.json'),\n",
       " PosixPath('data/val'),\n",
       " PosixPath('data/stupidstuff.json'),\n",
       " PosixPath('data/trn')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH/'trn'/'trn.txt', 'wb') as f:\n",
    "    f.write(text[:(len(text)*4)//5].encode('utf-8'))\n",
    "    \n",
    "with open(PATH/'val'/'val.txt', 'wb') as f:\n",
    "    f.write(text[:(len(text)*4)//5].encode('utf-8'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mmodels\u001b[0m/  reddit_jokes.json  stupidstuff.json  \u001b[01;34mtrn\u001b[0m/  \u001b[01;34mval\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "# TODO: Refactor to use pathlib\n",
    "PATH='data/'\n",
    "\n",
    "TRN_PATH = 'trn/'\n",
    "VAL_PATH = 'val/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, we have data partitioned into a train / val split, let's train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import vocab, data\n",
    "\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "from fastai import sgdr\n",
    "n_hidden = 256\n",
    "embeddings_sz = 42 # size of embeddings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: <torchtext.data.field.Field object at 0x7f82ddd2de10>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3097, 59, 1, 1586237)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=list)\n",
    "bs=64; bptt=8; n_fac=42; n_hidden=256\n",
    "\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
    "\n",
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz, bs, nl):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.nl = vocab_size,nl\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.rnn = nn.LSTM(embeddings_sz, n_hidden, nl, dropout=0.5)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, rnn_len):\n",
    "        bs = rnn_len[0].size(0)\n",
    "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(rnn_len), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.h = (V(torch.zeros(self.nl, bs, n_hidden)),\n",
    "                  V(torch.zeros(self.nl, bs, n_hidden)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulLSTM(len(chars)+1,embeddings_sz, 512, 2).cuda()\n",
    "lo = LayerOptimizer(optim.Adam, m, 1e-2, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{PATH}models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb275f1157c419d94f583790d00b328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.678402   1.633846  \n",
      "    1      1.598647   1.569825                                \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.56983])]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 2, lo.opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ce910ef34c46dcb0e4843b6abac7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.45979    1.407439  \n",
      "    1      1.503157   1.466166                                \n",
      "    2      1.401743   1.352008                                \n",
      "    3      1.534357   1.491397                                \n",
      "    4      1.470248   1.4311                                  \n",
      "    5      1.395231   1.353864                                \n",
      "    6      1.347714   1.300119                                \n",
      "    7      1.515952   1.477014                                \n",
      "    8      1.504134   1.46758                                 \n",
      "    9      1.479751   1.436342                                \n",
      "    10     1.44414    1.4045                                  \n",
      "    11     1.409773   1.366815                                \n",
      "    12     1.372315   1.325256                                \n",
      "    13     1.33591    1.284613                                \n",
      "    14     1.305532   1.260108                                \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.26011])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 2**4-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3b52f6b6904e5eb354758cb502db83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.305987   1.255392  \n",
      "    1      1.303189   1.252042                                \n",
      "    2      1.303568   1.249549                                \n",
      "    3      1.304508   1.248046                                \n",
      "    4      1.298945   1.244094                                \n",
      "    5      1.287011   1.241299                                \n",
      "    6      1.29135    1.240419                                \n",
      "    7      1.297407   1.240417                                \n",
      "    8      1.289933   1.236835                                \n",
      "    9      1.288126   1.233664                                \n",
      "    10     1.282984   1.230674                                \n",
      "    11     1.285248   1.228273                                \n",
      "    12     1.28556    1.226379                                \n",
      "    13     1.278316   1.225414                                \n",
      "    14     1.279952   1.225072                                \n",
      "    15     1.281672   1.227242                                \n",
      "    16     1.285722   1.224565                                \n",
      "    17     1.279322   1.222361                                \n",
      "    18     1.273744   1.219352                                \n",
      "    19     1.270972   1.217204                                \n",
      "    20     1.270796   1.214394                                \n",
      "    21     1.269306   1.212013                                \n",
      "    22     1.261479   1.210197                                \n",
      "    23     1.262181   1.208648                                \n",
      "    24     1.267498   1.206753                                \n",
      "    25     1.265441   1.205192                                \n",
      "    26     1.26141    1.204474                                \n",
      "    27     1.258798   1.203275                                \n",
      "    28     1.258248   1.202698                                \n",
      "    29     1.259984   1.202349                                \n",
      "    30     1.256367   1.202253                                \n",
      "    31     1.256322   1.202184                                \n",
      "    32     1.264003   1.204978                                \n",
      "    33     1.255325   1.203929                                \n",
      "    34     1.26248    1.201945                                \n",
      "    35     1.260373   1.199871                                \n",
      "    36     1.253527   1.197875                                \n",
      "    37     1.253453   1.195891                                \n",
      "    38     1.254937   1.194648                                \n",
      "    39     1.256329   1.192869                                \n",
      "    40     1.247332   1.191063                                \n",
      "    41     1.248783   1.189304                                \n",
      "    42     1.245804   1.18776                                 \n",
      "    43     1.245456   1.186132                                \n",
      "    44     1.250974   1.184398                                \n",
      "    45     1.246406   1.182823                                \n",
      "    46     1.245949   1.181393                                \n",
      "    47     1.238103   1.179839                                \n",
      "    48     1.242535   1.178673                                \n",
      "    49     1.243107   1.177935                                \n",
      "    50     1.244014   1.176888                                \n",
      "    51     1.240416   1.175902                                \n",
      "    52     1.233262   1.174914                                \n",
      "    53     1.236661   1.174272                                \n",
      "    54     1.234558   1.173462                                \n",
      "    55     1.235217   1.17256                                 \n",
      "    56     1.237265   1.171957                                \n",
      "    57     1.226023   1.171584                                \n",
      "    58     1.232252   1.171353                                \n",
      "    59     1.227445   1.171012                                \n",
      "    60     1.230203   1.170759                                \n",
      "    61     1.231854   1.170527                                \n",
      "    62     1.224868   1.170431                                \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.17043])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 2**6-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = TEXT.numericalize(inp)\n",
    "    p = m(VV(idxs.transpose(0,1)))\n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return TEXT.vocab.itos[to_np(r)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('into a b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('a ma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('blon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_next_n(inp, n):\n",
    "#     res = inp\n",
    "#     for i in range(n):\n",
    "#         c = get_next(inp)\n",
    "#         res += c\n",
    "#         inp = inp[1:]+c\n",
    "#     return res\n",
    "\n",
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "into a bad punch jack himself. xeoj  the words xeoj  how do you will have a best stands. we will be time! playing to people to them. xeoj  jerk gonna havmen.  xeoj  where aftey poop in the farms. amazunce jesus struggles. he proceeded gathers and says, \"but, survive?\"stedictle. \"doctor, \"mr. pengle after a sure. the wife fuck in the ended point. xeoj  i said \"dad, my wife built as well and a prize and whi\n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('into a b', 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blong, it withother, is a sec xeoj de pilg xeoj dick xeoj and nigged?* xeoj how four and one now.\"**wife: you took somete; it anonist, and paba and, man: i remus keepular. i can caughtyfe***\"yes\" 9.he run\n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('blon', 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what do you have a bad.\" xeoj  what would play him with my bodyle with my penis bottle of erectued. you sound xeoj  saunce xeoj  what chef nic?\"'miss as the popher has unfully gun.  xeoj  this movie- xeoj  teacher riding youx for their awe... if i'll make it chanced. xeoj  you knowing] black. after name dicks xeoj  two teacher radio one.0.\" xeoj  i met your brother, tomorrow xeoj  girl we need to be fourin\n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('what do y',400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_next_n_jokes(prompt, n):\n",
    "#     jokes = []\n",
    "#     c = ''\n",
    "#     for j in range(n):\n",
    "#         inp = prompt\n",
    "#         res = prompt\n",
    "#         while res[-5:-1]!=\"xeoj\":\n",
    "#             c = get_next(inp)\n",
    "#             res += c\n",
    "#             inp = inp[1:]+c\n",
    "#         jokes.append(res)\n",
    "#     return jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for joke in get_next_n_jokes(\"you hear about the university book store worker\",4):\n",
    "#     print(joke)\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for joke in get_next_n_jokes(\"i hate how you can't s\",4):\n",
    "#     print(joke)\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for joke in get_next_n_jokes('why women need legs',4):\n",
    "#     print(joke)\n",
    "#     print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
