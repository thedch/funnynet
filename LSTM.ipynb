{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funnynet\n",
    "\n",
    "## A neural network that makes jokes\n",
    "\n",
    "Special thanks to taivop for providing the [dataset](https://github.com/taivop/joke-dataset).\n",
    "\n",
    "This notebook is heavily inspired by [fastai NLP work](https://github.com/fastai/fastai/blob/master/courses/dl2/imdb.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "EOJ = 'xeoj'  # end of joke tag\n",
    "\n",
    "PATH=Path('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('data/val'), PosixPath('data/.ipynb_checkpoints'), PosixPath('data/trn'), PosixPath('data/stupidstuff.json'), PosixPath('data/models'), PosixPath('data/reddit_jokes.json')]\n"
     ]
    }
   ],
   "source": [
    "files = list(PATH.iterdir())\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in files:\n",
    "    if \"eddit\" in str(fname):\n",
    "        reddit_dataset = str(fname)\n",
    "    if \"upid\" in str(fname):\n",
    "        stupid_dataset = str(fname)\n",
    "reddit_jokes = json.load(open(reddit_dataset))\n",
    "stupid_jokes = json.load(open(stupid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194553"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reddit_jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'body': 'Now I have to say \"Leroy can you please paint the fence?\"',\n",
       " 'id': '5tz52q',\n",
       " 'score': 1,\n",
       " 'title': 'I hate how you cant even say black paint anymore'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_jokes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's discard all the jokes that have 0 score, as they aren't that helpful for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rated_jokes = [joke for joke in reddit_jokes if joke['score'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132992"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rated_jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172.94791416025024, 48526)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = [joke['score'] for joke in rated_jokes]\n",
    "np.mean(scores),np.max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f59023be160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "low_scores = [score for score in scores]\n",
    "plt.xscale('log', nonposx='clip')\n",
    "plt.ylim(ymax=200000)\n",
    "#plt.axes.set_ylim([0,200000])\n",
    "plt.hist(low_scores, bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I hate how you cant even say black paint anymore Now I have to say \"Leroy can you please paint the fence?\"'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_body = [joke['title']+' '+joke['body'] for joke in rated_jokes]\n",
    "title_body[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horrible, but formatted correctly. Now, let's combine all the jokes into one long string, using the `EOJ` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f59066bce48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_jokes = []\n",
    "for i in range(len(reddit_jokes)):\n",
    "    r_joke = reddit_jokes[i]\n",
    "    r_joke['rating']=round(math.log(r_joke['score']+random.randrange(1,10))/math.log(10)*5/2, 2)\n",
    "    if r_joke['rating']>5: # TODO: use max() here\n",
    "        r_joke['rating']=5\n",
    "    del r_joke['score'] \n",
    "    r_joke['body'] = r_joke['title']+\" \"+r_joke['body']\n",
    "    del r_joke['title']\n",
    "for s_joke in stupid_jokes:\n",
    "    del s_joke['category']\n",
    "\n",
    "combined = [joke['rating'] for joke in reddit_jokes]\n",
    "combined = combined + [joke['rating'] for joke in stupid_jokes]\n",
    "plt.hist(combined,bins=5);\n",
    "\n",
    "combined_jokes = reddit_jokes + stupid_jokes\n",
    "\n",
    "title_body = [joke['body']+' ' for joke in combined_jokes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "for joke in title_body:\n",
    "    text = text + ' ' + joke + ' ' + EOJ + ' '\n",
    "    if len(text) > 2700000: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls ‘Jesus Christ, are you still in there?'”  xeoj  You hear about the University book store worker w\n"
     ]
    }
   ],
   "source": [
    "len(text)\n",
    "print(text[1000:1100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 160\n",
      "['\\x00', '\\t', '\\n', '\\r', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '}', '~', '\\x9d', '\\xa0', '¡', '¢', '£', '«', '°', '´', '»', 'Ñ', '×', 'à', 'ä', 'è', 'é', 'ì', 'í', 'ñ', 'ó', 'ʖ', '͜', '͡', 'μ', 'π', '\\u2009', '\\u200b', '\\u200f', '–', '—', '‘', '’', '“', '”', '•', '…', '\\u2028', '″', '‽', '€', '√', '∫', '☝', '♻', '主', '人', '斋', '林', '浮', '白', '笑', '\\ufeff', '🇩', '🇰', '😁', '😂', '😇', '😈', '😊', '😋', '😎', '😨', '🤣']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)\n",
    "chars.insert(0, \"\\0\")\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears there are Emojis in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = {c: i for i, c in enumerate(chars)}\n",
    "indices_char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 45, 4, 76, 69, 88, 73, 4, 76, 83]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [char_indices[c] for c in text]\n",
    "\n",
    "idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I hate how you cant even say black paint anymore Now I have to say \"L'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partitioning the dataset and writing it to /data/trn/trn.txt and /data/val/val.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mmodels\u001b[0m/  reddit_jokes.json  stupidstuff.json  \u001b[01;34mtrn\u001b[0m/  \u001b[01;34mval\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "PATH='data/'\n",
    "\n",
    "TRN_PATH = 'trn/'\n",
    "VAL_PATH = 'val/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "%ls {PATH} # Don't do this, use pathlib(), it's a lot cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = open(TRN+\"trn.txt\",\"wb\")\n",
    "#rn.write(\"test\")\n",
    "trn.write(text[0:int(len(text)*4/5)].encode('utf-8'))#str(idx[0:int(len(idx)*2/3)]))\n",
    "trn.close()\n",
    "val = open(VAL+\"val.txt\",\"wb\")\n",
    "#al.write(\"test\")\n",
    "val.write(text[int(len(text)*4/5):len(text)-1].encode('utf-8'))#str(idx[int(len(idx)*2/3):len(idx)-1]))\n",
    "val.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three character model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2700100"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = 3\n",
    "c1_data = c2_data = c3_data = c4_data = []\n",
    "for i in range(0, len(idx)-cs, cs):\n",
    "    c1_data.append(idx[i])\n",
    "    c2_data.append(idx[i+1])\n",
    "    c3_data.append(idx[i+2])\n",
    "    c4_data.append(idx[i+3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the input and outputs of our RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.stack(c1_data)\n",
    "x2 = np.stack(c2_data)\n",
    "x3 = np.stack(c3_data)\n",
    "y  = np.stack(c4_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 256\n",
    "embeddings_sz = 42 #size of embeddings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These libraries require some setup, try the pip install git+https.github.com/... trick\n",
    "from fastai.io import *\n",
    "from fastai.conv_learner import *\n",
    "\n",
    "from fastai.column_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeCharRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.l_in = nn.Linear(embeddings_sz, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, c1, c2, c3):\n",
    "        in1 = F.relu(self.l_in(self.e(c1))) # Why relu?\n",
    "        in2 = F.relu(self.l_in(self.e(c2)))\n",
    "        in3 = F.relu(self.l_in(self.e(c3)))\n",
    "        \n",
    "        h = V(torch.zeros(in1.size()).cuda())\n",
    "        h = F.tanh(self.l_hidden(h+in1))\n",
    "        h = F.tanh(self.l_hidden(h+in2))\n",
    "        h = F.tanh(self.l_hidden(h+in3))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', [-1], np.stack([x1,x2,x3], axis=1), y, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ThreeCharRNN(vocab_size, embeddings_sz).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = iter(md.trn_dl)\n",
    "*xs,yt = next(train_iterator)\n",
    "t = model(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe58e7d5b6f4bcdbbf51a3289c97c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      0.003494   0.0       \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, md, epochs=1, opt=optimizer, crit=F.nll_loss) # The negative log likelihood loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(optimizer, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e157789e444251bab2d70bfa62aa78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      0.000194   0.0       \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, md, 1, optimizer, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: what is going on with the indentation here? Use 4 spaces, not 3\n",
    "\n",
    "# def get_next(input):\n",
    "#     running_indicies = [] # Use get_next_n() here\n",
    "#     indicies = []\n",
    "#     for char in input:\n",
    "#         running_indicies.append(char_indices[char])\n",
    "#     for i in range(10):\n",
    "#         indicies = np.array(running_indicies[-3:])\n",
    "#         indicies = T(indicies)\n",
    "#        prediction = model(*VV(indicies))\n",
    "#        pred_idx = np.argmax(to_np(prediction))\n",
    "#        running_indicies.append(pred_idx)\n",
    "#    result_chars = []\n",
    "#    for index in running_indicies:\n",
    "#        result_chars.append(chars[index])\n",
    "#    return result_chars\n",
    "\n",
    "\n",
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = model(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('y. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('blo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a bigger RNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_len=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_in_jokes = [[idx[i+j] for i in range(rnn_len)] for j in range(len(idx)-rnn_len)]\n",
    "# The above line and the below for loops are the same, just refactored to be easier to read\n",
    "\n",
    "char_input = []\n",
    "for j in range(len(idx)-rnn_len):\n",
    "    tmp = []\n",
    "    for i in range(rnn_len):\n",
    "        tmp.append(idx[i+j])\n",
    "    char_input.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_output = []\n",
    "for j in range(len(idx)-rnn_len):\n",
    "    char_output.append(idx[j+rnn_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.stack(char_input, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2700092, 8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2700092,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.stack(char_output)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4, 45,  4, 76, 69, 88, 73,  4],\n",
       "       [45,  4, 76, 69, 88, 73,  4, 76],\n",
       "       [ 4, 76, 69, 88, 73,  4, 76, 83],\n",
       "       [76, 69, 88, 73,  4, 76, 83, 91],\n",
       "       [69, 88, 73,  4, 76, 83, 91,  4],\n",
       "       [88, 73,  4, 76, 83, 91,  4, 93],\n",
       "       [73,  4, 76, 83, 91,  4, 93, 83],\n",
       "       [ 4, 76, 83, 91,  4, 93, 83, 89]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:rnn_len,:rnn_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y[:rnn_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(idx)-rnn_len-1)\n",
    "# val_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = ColumnarModelData.from_arrays('.', val_idx, xs, y, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLoopModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.l_in = nn.Linear(embeddings_sz, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *rnn_len):\n",
    "#         pdb.set_trace()\n",
    "        bs = rnn_len[0].size(0)\n",
    "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
    "        for c in rnn_len:\n",
    "            inp = F.relu(self.l_in(self.e(c)))\n",
    "            h = F.tanh(self.l_hidden(h+inp))\n",
    "            \n",
    "        return F.log_softmax(self.l_out(h), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharLoopModel(vocab_size, embeddings_sz).cuda()\n",
    "opt = optim.Adam(model.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b03220016d42dd9ce6dda7a7842b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      2.075454   2.111557  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.111557]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, epochs=1, opt=opt, crit=F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc4363241c5475ea2c04f6cd4eeccdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.778078   1.789337  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7893368]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, epochs=1, opt=opt, crit=F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' a blond')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('into a b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'into a be the be the be the be the be the be the'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_n('into a b', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLoopConcatModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.l_in = nn.Linear(embeddings_sz+n_hidden, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *rnn_len):\n",
    "        bs = rnn_len[0].size(0)\n",
    "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
    "        for c in rnn_len:\n",
    "            inp = torch.cat((h, self.e(c)), 1)\n",
    "            inp = F.relu(self.l_in(inp))\n",
    "            h = F.tanh(self.l_hidden(inp))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharLoopConcatModel(vocab_size, embeddings_sz).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)\n",
    "t = m(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4dcbf47a5004b24922139c81083e3f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      0.00011    2e-06     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9073486e-06]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea42d8d0793041b6b11d290ba7974d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      7e-06      0.0       \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('wome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('beca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('char')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN with pytorch\n",
    "\n",
    "### Model with Multiple Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.rnn = nn.RNN(embeddings_sz, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *rnn_len):\n",
    "        #print(\"rnn_len: \"+str(rnn_len))\n",
    "        bs = rnn_len[0].size(0)\n",
    "        h = V(torch.zeros(1, bs, n_hidden))\n",
    "        inp = self.e(torch.stack(rnn_len))\n",
    "        outp,h = self.rnn(inp, h)\n",
    "        \n",
    "        return F.log_softmax(self.l_out(outp[-1]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharRnn(vocab_size, embeddings_sz).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 42])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m.e(V(torch.stack(xs)))\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 512, 256]), torch.Size([1, 512, 256]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht = V(torch.zeros(1, 512,n_hidden))\n",
    "outp, hn = m.rnn(t, ht)\n",
    "outp.size(), hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 160])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m(*V(xs)); t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e025a068bf4800ac32fce51ebebb8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      1.8e-05    2e-06     \n",
      "    1      0.000178   0.0                                         \n",
      "    2      0.0        0.0                                         \n",
      "    3      3.4e-05    0.0                                         \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72501a2ebd0a49088a01c3e77d0f5342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      0.0        0.0       \n",
      "    1      0.0        0.0                                         \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 2, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for thosoooooooooooooooooooooooooooooooooooooooo'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_n('for thos', 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi output model\n",
    "\n",
    "### Setup\n",
    "\n",
    "Let's take non-overallping sets of characters this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_in_dat = [[idx[i+j] for i in range(rnn_len)] for j in range(0, len(idx)-rnn_len-1, rnn_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_out_dat = [[idx[i+j] for i in range(rnn_len)] for j in range(1, len(idx)-rnn_len, rnn_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337512, 8)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = np.stack(c_in_dat)\n",
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4, 45,  4, 76, 69, 88, 73,  4],\n",
       "       [76, 83, 91,  4, 93, 83, 89,  4],\n",
       "       [71, 69, 82, 88,  4, 73, 90, 73],\n",
       "       [82,  4, 87, 69, 93,  4, 70, 80],\n",
       "       [69, 71, 79,  4, 84, 69, 77, 82],\n",
       "       [88,  4, 69, 82, 93, 81, 83, 86],\n",
       "       [73,  4, 50, 83, 91,  4, 45,  4],\n",
       "       [76, 69, 90, 73,  4, 88, 83,  4]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:rnn_len,:rnn_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337512, 8)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = np.stack(c_out_dat)\n",
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45,  4, 76, 69, 88, 73,  4, 76],\n",
       "       [83, 91,  4, 93, 83, 89,  4, 71],\n",
       "       [69, 82, 88,  4, 73, 90, 73, 82],\n",
       "       [ 4, 87, 69, 93,  4, 70, 80, 69],\n",
       "       [71, 79,  4, 84, 69, 77, 82, 88],\n",
       "       [ 4, 69, 82, 93, 81, 83, 86, 73],\n",
       "       [ 4, 50, 83, 91,  4, 45,  4, 76],\n",
       "       [69, 90, 73,  4, 88, 83,  4, 87]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[:rnn_len,:rnn_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(xs)-rnn_len-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', val_idx, xs, ys, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.rnn = nn.RNN(embeddings_sz, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *rnn_len):\n",
    "        bs = rnn_len[0].size(0)\n",
    "        h = V(torch.zeros(1, bs, n_hidden))\n",
    "        inp = self.e(torch.stack(rnn_len))\n",
    "        outp,h = self.rnn(inp, h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqRnn(vocab_size, embeddings_sz).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xst,yt = next(it)\n",
    "#t = m(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_loss_seq(inp, targ):\n",
    "    sl,bs,nh = inp.size()\n",
    "    targ = targ.transpose(0,1).contiguous().view(-1)\n",
    "    return F.nll_loss(inp.view(-1,nh), targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68e4905c4c34286b2bb6c547c9f8b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      2.084811   2.060115  \n",
      "    1      1.935882   1.92809                               \n",
      "    2      1.870535   1.871492                              \n",
      "    3      1.83798    1.838083                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8380834]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e50c574f8b4a57953aee2d2c270d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.811239   1.82215   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.82215]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity init!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqRnn(vocab_size, embeddings_sz).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    1     0     0  ...      0     0     0\n",
       "    0     1     0  ...      0     0     0\n",
       "    0     0     1  ...      0     0     0\n",
       "       ...          ⋱          ...       \n",
       "    0     0     0  ...      1     0     0\n",
       "    0     0     0  ...      0     1     0\n",
       "    0     0     0  ...      0     0     1\n",
       "[torch.cuda.FloatTensor of size 256x256 (GPU 0)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.rnn.weight_hh_l0.data.copy_(torch.eye(n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86fc1a5e785047ac9cbf65ab7bef11d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      2.005716   1.98064   \n",
      "    1      1.945557   1.942255                              \n",
      "    2      1.912102   1.9171                                \n",
      "    3      1.900668   1.903607                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9036067]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130e55e602654d49866771dd74272b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.823887   1.830701  \n",
      " 17%|█▋        | 88/528 [00:02<00:14, 31.03it/s, loss=1.82]"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful model\n",
    "\n",
    "### Adding State: RNN\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import vocab, data\n",
    "\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='data/'\n",
    "\n",
    "TRN_PATH = 'trn/'\n",
    "VAL_PATH = 'val/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like this next part assumes we have already partitioned the data into trn/trn.txt and val/val.txt for training and validation sets, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=list)\n",
    "print(\"TEXT: \"+str(TEXT))\n",
    "bs=64; bptt=8; n_fac=42; n_hidden=256\n",
    "\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
    "\n",
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs):\n",
    "        self.vocab_size = vocab_size\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulRnn(md.nt, n_fac, 512).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)\n",
    "\n",
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "Now we will try an LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import vocab, data\n",
    "\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "from fastai import sgdr\n",
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_idx = get_cv_idxs(len(xs)-rnn_len-1)\n",
    "# print(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(xs)\n",
    "# print(ys)\n",
    "# md = ColumnarModelData.from_arrays('.', val_idx, xs, ys, bs=512)\n",
    "# print(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz, bs, nl):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.nl = vocab_size,nl\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.rnn = nn.LSTM(embeddings_sz, n_hidden, nl, dropout=0.5)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, rnn_len):\n",
    "        bs = rnn_len[0].size(0)\n",
    "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(rnn_len), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.h = (V(torch.zeros(self.nl, bs, n_hidden)),\n",
    "                  V(torch.zeros(self.nl, bs, n_hidden)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulLSTM(len(chars)+1,embeddings_sz, 512, 2).cuda()\n",
    "lo = LayerOptimizer(optim.Adam, m, 1e-2, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{PATH}models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(m, md, 2, lo.opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## He trains for 2^6 epochs... I'm not waiting that long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 2**6-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 2**6-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = TEXT.numericalize(inp)\n",
    "    p = m(VV(idxs.transpose(0,1)))\n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return TEXT.vocab.itos[to_np(r)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_next('into a b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_next('a ma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_next('blon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_next_n('into a b', 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_next_n('blon', 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_next_n('what do y',400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n_jokes(prompt,n):\n",
    "    jokes = []\n",
    "    c = ''\n",
    "    for j in range(n):\n",
    "        inp = prompt\n",
    "        res = prompt\n",
    "        while res[-5:-1]!=\"xeoj\":\n",
    "            c = get_next(inp)\n",
    "            res += c\n",
    "            inp = inp[1:]+c\n",
    "        jokes.append(res)\n",
    "    return jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for joke in get_next_n_jokes('the blon',4):\n",
    "    print(joke)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for joke in get_next_n_jokes('he smashes the bir',4):\n",
    "    print(joke)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for joke in get_next_n_jokes('what do you get wh',4):\n",
    "    print(joke)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for joke in get_next_n_jokes('a sunday school teacher',4):\n",
    "    print(joke)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for joke in get_next_n_jokes('why women need legs',4):\n",
    "    print(joke)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for joke in get_next_n_jokes(\"i hate how you can't s\",4):\n",
    "    print(joke)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for joke in get_next_n_jokes(\"you hear about the university book store worker\",4):\n",
    "    print(joke)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
