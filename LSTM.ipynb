{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funnynet\n",
    "\n",
    "## A neural network that makes jokes\n",
    "\n",
    "Special thanks to taivop for providing the [dataset](https://github.com/taivop/joke-dataset).\n",
    "\n",
    "This notebook is heavily inspired by [fastai NLP work](https://github.com/fastai/fastai/blob/master/courses/dl2/imdb.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "EOJ = 'xeoj'  # end of joke tag\n",
    "\n",
    "PATH=Path('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/models'),\n",
       " PosixPath('data/reddit_jokes.json'),\n",
       " PosixPath('data/val'),\n",
       " PosixPath('data/stupidstuff.json'),\n",
       " PosixPath('data/trn')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = list(PATH.iterdir())\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in files:\n",
    "    if \"reddit_jokes.json\" in str(fname):\n",
    "        reddit_dataset = str(fname)\n",
    "    if \"stupidstuff.json\" in str(fname):\n",
    "        stupid_dataset = str(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_jokes = json.load(open(reddit_dataset))\n",
    "stupid_jokes = json.load(open(stupid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194553"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reddit_jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'body': 'Now I have to say \"Leroy can you please paint the fence?\"',\n",
       " 'id': '5tz52q',\n",
       " 'score': 1,\n",
       " 'title': 'I hate how you cant even say black paint anymore'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_jokes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I hate how you cant even say black paint anymore Now I have to say \"Leroy can you please paint the fence?\"'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_plus_body = [joke['title'] + ' ' + joke['body'] for joke in reddit_jokes]\n",
    "title_plus_body[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horrible, but formatted correctly. \n",
    "\n",
    "# Setup, creating .txt files to train LSTM on\n",
    "\n",
    "Partitioning the dataset and writing it to /data/trn/trn.txt and /data/val/val.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(PATH/'val').mkdir(exist_ok=True)\n",
    "(PATH/'trn').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accepted_chars = \"!\\\"\\'“”‘’(),$*-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz \\n\"\n",
    "# print(accepted_chars)\n",
    "\n",
    "num_jokes = len(title_plus_body)\n",
    "\n",
    "with open(PATH/'trn'/'trn.txt', 'wb') as trn, open(PATH/'val'/'val.txt', 'wb') as val:\n",
    "    for i in range(num_jokes):\n",
    "        # Strip formatting\n",
    "        joke = ''.join([char if ord(char) < 128 else ' ' for char in title_plus_body[i]]) + ' ' + EOJ + ' '\n",
    "        if i % 5 == 0: # Save to validation set\n",
    "            val.write(joke.encode('utf-8'))\n",
    "        else: # Save to training set\n",
    "            trn.write(joke.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/models'),\n",
       " PosixPath('data/reddit_jokes.json'),\n",
       " PosixPath('data/val'),\n",
       " PosixPath('data/stupidstuff.json'),\n",
       " PosixPath('data/trn')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mmodels\u001b[0m/  reddit_jokes.json  stupidstuff.json  \u001b[01;34mtrn\u001b[0m/  \u001b[01;34mval\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "# TODO: Refactor to use pathlib\n",
    "PATH='data/'\n",
    "\n",
    "TRN_PATH = 'trn/'\n",
    "VAL_PATH = 'val/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, we have data partitioned into a train / val split, let's train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import vocab, data\n",
    "\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "from fastai import sgdr\n",
    "n_hidden = 256\n",
    "embeddings_sz = 42 # size of embeddings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77405, 73, 1, 39632371)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=list)\n",
    "bs=64; bptt=8; n_fac=42; n_hidden=256\n",
    "\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
    "\n",
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`md.nt` is the vocab size here. It's the same as `len(TEXT.vocab)` under the hood. (see `LanguageModelData` source)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "??LanguageModelData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz, bs, nl):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.nl = vocab_size,nl\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.rnn = nn.LSTM(embeddings_sz, n_hidden, nl, dropout=0.5)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, rnn_len):\n",
    "        bs = rnn_len[0].size(0)\n",
    "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(rnn_len), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.h = (V(torch.zeros(self.nl, bs, n_hidden)),\n",
    "                  V(torch.zeros(self.nl, bs, n_hidden)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulLSTM(len(TEXT.vocab),embeddings_sz, 512, 2).cuda()\n",
    "lo = LayerOptimizer(optim.Adam, m, 1e-2, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{PATH}models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45dd853548034efb903ea23e32dbe3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      1.515767   1.495247  \n",
      "    1      1.513658   1.484518                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.48452])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 2, lo.opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb3bbefcd1b4dbcaf93f53417e58d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      1.309037   1.280966  \n",
      "    1      1.429574   1.416574                                  \n",
      "    2      1.291161   1.263028                                  \n",
      "    3      1.478619   1.472945                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.47295])]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 4, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c925279935422194b06a1ddd58e9c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      1.30442    1.275652  \n",
      "    1      1.416012   1.404496                                  \n",
      "    2      1.285423   1.260299                                  \n",
      "    3      1.458385   1.450095                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.45009])]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 4, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = TEXT.numericalize(inp)\n",
    "    p = m(VV(idxs.transpose(0,1)))\n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return TEXT.vocab.itos[to_np(r)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('into a b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('a ma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('blon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_next_n(inp, n):\n",
    "#     res = inp\n",
    "#     for i in range(n):\n",
    "#         c = get_next(inp)\n",
    "#         res += c\n",
    "#         inp = inp[1:]+c\n",
    "#     return res\n",
    "\n",
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "into a boy calls into the people prack and slippe xounchlock bridge xeoj why does the best only publes over himsned kick and says, \"chuffur, treattent, the ass so the busched exciter were so everywhe always a fither brings him. the viden. \"hey give me: \"find!\" xeoj i'll killed, are nater.  so, if the armuns to nrot ide there looks to he water has the little but it cream harded.after a ravol-while from the\n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('into a b', 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blong, it withother, is a sec xeoj de pilg xeoj dick xeoj and nigged?* xeoj how four and one now.\"**wife: you took somete; it anonist, and paba and, man: i remus keepular. i can caughtyfe***\"yes\" 9.he run\n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('blon', 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what do you have a bad.\" xeoj  what would play him with my bodyle with my penis bottle of erectued. you sound xeoj  saunce xeoj  what chef nic?\"'miss as the popher has unfully gun.  xeoj  this movie- xeoj  teacher riding youx for their awe... if i'll make it chanced. xeoj  you knowing] black. after name dicks xeoj  two teacher radio one.0.\" xeoj  i met your brother, tomorrow xeoj  girl we need to be fourin\n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('what do y',400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_next_n_jokes(prompt, n):\n",
    "#     jokes = []\n",
    "#     c = ''\n",
    "#     for j in range(n):\n",
    "#         inp = prompt\n",
    "#         res = prompt\n",
    "#         while res[-5:-1]!=\"xeoj\":\n",
    "#             c = get_next(inp)\n",
    "#             res += c\n",
    "#             inp = inp[1:]+c\n",
    "#         jokes.append(res)\n",
    "#     return jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for joke in get_next_n_jokes(\"you hear about the university book store worker\",4):\n",
    "#     print(joke)\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for joke in get_next_n_jokes(\"i hate how you can't s\",4):\n",
    "#     print(joke)\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for joke in get_next_n_jokes('why women need legs',4):\n",
    "#     print(joke)\n",
    "#     print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
