{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funnynet\n",
    "\n",
    "## A neural network that makes jokes\n",
    "\n",
    "Special thanks to taivop for providing the [dataset](https://github.com/taivop/joke-dataset).\n",
    "\n",
    "This notebook is heavily inspired by [fastai NLP work](https://github.com/fastai/fastai/blob/master/courses/dl2/imdb.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "EOJ = 'xeoj'  # end of joke tag\n",
    "\n",
    "PATH=Path('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('data/reddit_jokes.json'), PosixPath('data/stupidstuff.json')]\n"
     ]
    }
   ],
   "source": [
    "files = list(PATH.iterdir())\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in files:\n",
    "    if \"eddit\" in str(fname):\n",
    "        reddit_dataset = str(fname)\n",
    "    if \"upid\" in str(fname):\n",
    "        stupid_dataset = str(fname)\n",
    "reddit_jokes = json.load(open(reddit_dataset))\n",
    "stupid_jokes = json.load(open(stupid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194553"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reddit_jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'body': 'Now I have to say \"Leroy can you please paint the fence?\"',\n",
       " 'id': '5tz52q',\n",
       " 'score': 1,\n",
       " 'title': 'I hate how you cant even say black paint anymore'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_jokes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's discard all the jokes that have 0 score, as they aren't that helpful for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rated_jokes = [joke for joke in reddit_jokes if joke['score'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132992"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rated_jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172.94791416025024, 48526)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = [joke['score'] for joke in rated_jokes]\n",
    "np.mean(scores),np.max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4d53ab6b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "low_scores = [score for score in scores]\n",
    "plt.xscale('log', nonposx='clip')\n",
    "plt.ylim(ymax=200000)\n",
    "#plt.axes.set_ylim([0,200000])\n",
    "plt.hist(low_scores, bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I hate how you cant even say black paint anymore Now I have to say \"Leroy can you please paint the fence?\"'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_body = [joke['title']+' '+joke['body'] for joke in rated_jokes]\n",
    "title_body[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horrible, but formatted correctly. Now, let's combine all the jokes into one long string, using the `EOJ` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4d5af2aef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_jokes = []\n",
    "for i in range(len(reddit_jokes)):\n",
    "    r_joke = reddit_jokes[i]\n",
    "    r_joke['rating']=round(math.log(r_joke['score']+random.randrange(1,10))/math.log(10)*5/2, 2)\n",
    "    if r_joke['rating']>5: # TODO: use max() here\n",
    "        r_joke['rating']=5\n",
    "    del r_joke['score'] \n",
    "    r_joke['body'] = r_joke['title']+\" \"+r_joke['body']\n",
    "    del r_joke['title']\n",
    "for s_joke in stupid_jokes:\n",
    "    del s_joke['category']\n",
    "\n",
    "combined = [joke['rating'] for joke in reddit_jokes]\n",
    "combined = combined + [joke['rating'] for joke in stupid_jokes]\n",
    "plt.hist(combined,bins=5);\n",
    "\n",
    "combined_jokes = reddit_jokes + stupid_jokes\n",
    "\n",
    "title_body = [joke['body']+' ' for joke in combined_jokes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "for joke in title_body:\n",
    "    text = text + ' ' + joke + ' ' + EOJ + ' '\n",
    "    if len(text) > 800000: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit me, not that they were going to destroy the housing market 20 years later. xeoj  My boss said to\n"
     ]
    }
   ],
   "source": [
    "len(text)\n",
    "print(text[1000:1100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 127\n",
      "['\\x00', '\\n', '\\r', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~', '\\x9d', '\\xa0', '¬¢', '¬£', '¬∞', '¬¥', '√®', '√©', '√±', '√≥', ' ñ', 'Õú', 'Õ°', 'Œº', 'œÄ', '‚Äì', '‚Äî', '‚Äò', '‚Äô', '‚Äú', '‚Äù', '‚Ä¢', '‚Ä¶', '‚Ç¨', '‚àö', '‚à´', '\\ufeff', 'üá©', 'üá∞', 'üòÇ', 'üò®', 'ü§£']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)\n",
    "chars.insert(0, \"\\0\")\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\x00', '\\n', '\\r', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~', '\\x9d', '\\xa0', '¬¢', '¬£', '¬∞', '¬¥', '√®', '√©', '√±', '√≥', ' ñ', 'Õú', 'Õ°', 'Œº', 'œÄ', '‚Äì', '‚Äî', '‚Äò', '‚Äô', '‚Äú', '‚Äù', '‚Ä¢', '‚Ä¶', '‚Ç¨', '‚àö', '‚à´', '\\ufeff', 'üá©', 'üá∞', 'üòÇ', 'üò®', 'ü§£']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears there are Emojis in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = {c: i for i, c in enumerate(chars)}\n",
    "indices_char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 44, 3, 75, 68, 87, 72, 3, 75, 82]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [char_indices[c] for c in text]\n",
    "\n",
    "idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I hate how you cant even say black paint anymore Now I have to say \"L'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partitioning the dataset and writing it to /data/trn/trn.txt and /data/val/val.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reddit_jokes.json  stupidstuff.json\r\n"
     ]
    }
   ],
   "source": [
    "PATH='data/'\n",
    "\n",
    "TRN_PATH = 'trn/'\n",
    "VAL_PATH = 'val/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "%ls {PATH} # Don't do this, use pathlib(), it's a lot cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = open(TRN+\"trn.txt\",\"w\")\n",
    "trn.write(\"test\")\n",
    "trn.write(str(idx[0:int(len(idx)*2/3)]))\n",
    "trn.close()\n",
    "val = open(VAL+\"val.txt\",\"w\")\n",
    "val.write(\"test\")\n",
    "val.write(str(idx[int(len(idx)*2/3):len(idx)-1]))\n",
    "val.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three character model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800120"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = 3\n",
    "c1_data = c2_data = c3_data = c4_data = []\n",
    "for i in range(0, len(idx)-cs, cs):\n",
    "    c1_data.append(idx[i])\n",
    "    c2_data.append(idx[i+1])\n",
    "    c3_data.append(idx[i+2])\n",
    "    c4_data.append(idx[i+3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the input and outputs of our RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.stack(c1_data)\n",
    "x2 = np.stack(c2_data)\n",
    "x3 = np.stack(c3_data)\n",
    "y  = np.stack(c4_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 256\n",
    "embeddings_sz = 42 #size of embeddings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These libraries require some setup, try the pip install git+https.github.com/... trick\n",
    "from fastai.io import *\n",
    "from fastai.conv_learner import *\n",
    "\n",
    "from fastai.column_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeCharRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.l_in = nn.Linear(embeddings_sz, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, c1, c2, c3):\n",
    "        in1 = F.relu(self.l_in(self.e(c1))) # Why relu?\n",
    "        in2 = F.relu(self.l_in(self.e(c2)))\n",
    "        in3 = F.relu(self.l_in(self.e(c3)))\n",
    "        \n",
    "        h = V(torch.zeros(in1.size()).cuda())\n",
    "        h = F.tanh(self.l_hidden(h+in1))\n",
    "        h = F.tanh(self.l_hidden(h+in2))\n",
    "        h = F.tanh(self.l_hidden(h+in3))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', [-1], np.stack([x1,x2,x3], axis=1), y, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ThreeCharRNN(vocab_size, embeddings_sz).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = iter(md.trn_dl)\n",
    "*xs,yt = next(train_iterator)\n",
    "t = model(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03aeccb2cc0c46d48c0aa05e8870d849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      0.002471   2e-06     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.])]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, md, n_epochs=1, opt=optimizer, crit=F.nll_loss) # The negative log likelihood loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(optimizer, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04baffb4203489e8511815ed7584aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      0.000195   6e-06     \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.00001])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, md, 1, optimizer, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: what is going on with the indentation here? Use 4 spaces, not 3\n",
    "\n",
    "# def get_next(input):\n",
    "#     running_indicies = [] # Use get_next_n() here\n",
    "#     indicies = []\n",
    "#     for char in input:\n",
    "#         running_indicies.append(char_indices[char])\n",
    "#     for i in range(10):\n",
    "#         indicies = np.array(running_indicies[-3:])\n",
    "#         indicies = T(indicies)\n",
    "#        prediction = model(*VV(indicies))\n",
    "#        pred_idx = np.argmax(to_np(prediction))\n",
    "#        running_indicies.append(pred_idx)\n",
    "#    result_chars = []\n",
    "#    for index in running_indicies:\n",
    "#        result_chars.append(chars[index])\n",
    "#    return result_chars\n",
    "\n",
    "\n",
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = model(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('y. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('blo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a bigger RNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_len=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_in_jokes = [[idx[i+j] for i in range(rnn_len)] for j in range(len(idx)-rnn_len)]\n",
    "# The above line and the below for loops are the same, just refactored to be easier to read\n",
    "\n",
    "char_input = []\n",
    "for j in range(len(idx)-rnn_len):\n",
    "    tmp = []\n",
    "    for i in range(rnn_len):\n",
    "        tmp.append(idx[i+j])\n",
    "    char_input.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_output = []\n",
    "for j in range(len(idx)-rnn_len):\n",
    "    char_output.append(idx[j+rnn_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.stack(char_input, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800112, 8)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800112,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.stack(char_output)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, 44,  3, 75, 68, 87, 72,  3],\n",
       "       [44,  3, 75, 68, 87, 72,  3, 75],\n",
       "       [ 3, 75, 68, 87, 72,  3, 75, 82],\n",
       "       [75, 68, 87, 72,  3, 75, 82, 90],\n",
       "       [68, 87, 72,  3, 75, 82, 90,  3],\n",
       "       [87, 72,  3, 75, 82, 90,  3, 92],\n",
       "       [72,  3, 75, 82, 90,  3, 92, 82],\n",
       "       [ 3, 75, 82, 90,  3, 92, 82, 88]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:rnn_len,:rnn_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y[:rnn_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(idx)-rnn_len-1)\n",
    "# val_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = ColumnarModelData.from_arrays('.', val_idx, xs, y, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLoopModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.l_in = nn.Linear(embeddings_sz, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *rnn_len):\n",
    "#         pdb.set_trace()\n",
    "        bs = rnn_len[0].size(0)\n",
    "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
    "        for c in rnn_len:\n",
    "            inp = F.relu(self.l_in(self.e(c)))\n",
    "            h = F.tanh(self.l_hidden(h+inp))\n",
    "            \n",
    "        return F.log_softmax(self.l_out(h), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharLoopModel(vocab_size, embeddings_sz).cuda()\n",
    "opt = optim.Adam(model.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320f393b8e4c439684bacf227f005610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      2.094388   2.088229  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([2.08823])]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, n_epochs=1, opt=opt, crit=F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdc38142c624f1d9574ff11ee1e28ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.836378   1.834439  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.83444])]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, n_epochs=1, opt=opt, crit=F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' a blond')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('into a b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'into a been the says a for the says a for the sa'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_n('into a b', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLoopConcatModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.l_in = nn.Linear(embeddings_sz+n_hidden, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *rnn_len):\n",
    "        bs = rnn_len[0].size(0)\n",
    "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
    "        for c in rnn_len:\n",
    "            inp = torch.cat((h, self.e(c)), 1)\n",
    "            inp = F.relu(self.l_in(inp))\n",
    "            h = F.tanh(self.l_hidden(inp))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharLoopConcatModel(vocab_size, embeddings_sz).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)\n",
    "t = m(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a3692675b2408cb9758d86d35b9fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      0.000454   0.000239  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.00024])]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2c95400035476ba941a3b3743f2274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      0.000124   0.00018   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.00018])]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('wome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('beca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('char')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN with pytorch\n",
    "\n",
    "### Model with Multiple Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.rnn = nn.RNN(embeddings_sz, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *rnn_len):\n",
    "        #print(\"rnn_len: \"+str(rnn_len))\n",
    "        bs = rnn_len[0].size(0)\n",
    "        h = V(torch.zeros(1, bs, n_hidden))\n",
    "        inp = self.e(torch.stack(rnn_len))\n",
    "        outp,h = self.rnn(inp, h)\n",
    "        \n",
    "        return F.log_softmax(self.l_out(outp[-1]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharRnn(vocab_size, embeddings_sz).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 42])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m.e(V(torch.stack(xs)))\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 512, 256]), torch.Size([1, 512, 256]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht = V(torch.zeros(1, 512,n_hidden))\n",
    "outp, hn = m.rnn(t, ht)\n",
    "outp.size(), hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 127])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m(*V(xs)); t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2038daa3d921468aafdffc13188452aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      0.00056    0.000258  \n",
      "    1      0.00024    4.6e-05                                     \n",
      "    2      1.8e-05    1.3e-05                                     \n",
      "    3      2e-06      4e-06                                       \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.])]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e81b4f556fc4c85b0a62b2548f049a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                    \n",
      "    0      2e-06      4e-06     \n",
      "    1      1e-06      2e-06                                       \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.])]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 2, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for thosoooooooooooooooooooooooooooooooooooooooo'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_n('for thos', 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi output model\n",
    "\n",
    "### Setup\n",
    "\n",
    "Let's take non-overallping sets of characters this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_in_dat = [[idx[i+j] for i in range(rnn_len)] for j in range(0, len(idx)-rnn_len-1, rnn_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_out_dat = [[idx[i+j] for i in range(rnn_len)] for j in range(1, len(idx)-rnn_len, rnn_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100014, 8)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = np.stack(c_in_dat)\n",
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, 44,  3, 75, 68, 87, 72,  3],\n",
       "       [75, 82, 90,  3, 92, 82, 88,  3],\n",
       "       [70, 68, 81, 87,  3, 72, 89, 72],\n",
       "       [81,  3, 86, 68, 92,  3, 69, 79],\n",
       "       [68, 70, 78,  3, 83, 68, 76, 81],\n",
       "       [87,  3, 68, 81, 92, 80, 82, 85],\n",
       "       [72,  3, 49, 82, 90,  3, 44,  3],\n",
       "       [75, 68, 89, 72,  3, 87, 82,  3]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:rnn_len,:rnn_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100014, 8)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = np.stack(c_out_dat)\n",
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44,  3, 75, 68, 87, 72,  3, 75],\n",
       "       [82, 90,  3, 92, 82, 88,  3, 70],\n",
       "       [68, 81, 87,  3, 72, 89, 72, 81],\n",
       "       [ 3, 86, 68, 92,  3, 69, 79, 68],\n",
       "       [70, 78,  3, 83, 68, 76, 81, 87],\n",
       "       [ 3, 68, 81, 92, 80, 82, 85, 72],\n",
       "       [ 3, 49, 82, 90,  3, 44,  3, 75],\n",
       "       [68, 89, 72,  3, 87, 82,  3, 86]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[:rnn_len,:rnn_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(xs)-rnn_len-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', val_idx, xs, ys, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.rnn = nn.RNN(embeddings_sz, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *rnn_len):\n",
    "        bs = rnn_len[0].size(0)\n",
    "        h = V(torch.zeros(1, bs, n_hidden))\n",
    "        inp = self.e(torch.stack(rnn_len))\n",
    "        outp,h = self.rnn(inp, h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqRnn(vocab_size, embeddings_sz).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xst,yt = next(it)\n",
    "#t = m(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_loss_seq(inp, targ):\n",
    "    sl,bs,nh = inp.size()\n",
    "    targ = targ.transpose(0,1).contiguous().view(-1)\n",
    "    return F.nll_loss(inp.view(-1,nh), targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e521c938e0941fcbc7afa95521f4235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      2.54212    2.384332  \n",
      "    1      2.240772   2.183059                              \n",
      "    2      2.109145   2.080348                              \n",
      "    3      2.033118   2.016263                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([2.01626])]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83780e360cd0409cbb3f41393d0f8543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                             \n",
      "    0      1.997236   2.002939  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([2.00294])]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity init!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqRnn(vocab_size, embeddings_sz).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    1     0     0  ...      0     0     0\n",
       "    0     1     0  ...      0     0     0\n",
       "    0     0     1  ...      0     0     0\n",
       "       ...          ‚ã±          ...       \n",
       "    0     0     0  ...      1     0     0\n",
       "    0     0     0  ...      0     1     0\n",
       "    0     0     0  ...      0     0     1\n",
       "[torch.cuda.FloatTensor of size 256x256 (GPU 0)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.rnn.weight_hh_l0.data.copy_(torch.eye(n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7c1175073a46a88875d49e08cde094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      2.244507   2.137505  \n",
      "    1      2.053069   2.028961                              \n",
      "    2      1.980946   1.987566                              \n",
      "    3      1.940639   1.951869                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.95187])]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52cb98653b0f43c9aaf09b7f0944fbff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.860224   1.877847  \n",
      "    1      1.847886   1.871097                              \n",
      "    2      1.842195   1.866956                              \n",
      "    3      1.835162   1.86353                               \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.86353])]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful model\n",
    "\n",
    "### Adding State: RNN\n",
    "\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import vocab, data\n",
    "\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reddit_jokes.json  stupidstuff.json  \u001b[0m\u001b[01;34mtrn\u001b[0m/  \u001b[01;34mval\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "PATH='data/'\n",
    "\n",
    "TRN_PATH = 'trn/'\n",
    "VAL_PATH = 'val/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like this next part assumes we have already partitioned the data into trn/trn.txt and val/val.txt for training and validation sets, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: <torchtext.data.field.Field object at 0x7f0b4b471668>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3952, 14, 1, 2024278)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=list)\n",
    "print(\"TEXT: \"+str(TEXT))\n",
    "bs=64; bptt=8; n_fac=42; n_hidden=256\n",
    "\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
    "\n",
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs):\n",
    "        self.vocab_size = vocab_size\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulRnn(md.nt, n_fac, 512).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfcf7feebc46410f89d59197fb851a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.525814   0.532849  \n",
      "    1      0.493108   0.5048                                    \n",
      "    2      0.481015   0.494576                                  \n",
      "    3      0.470392   0.482152                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.48215])]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e503c7214b4d56a9864075b61d58da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.435904   0.457091  \n",
      "    1      0.431785   0.453439                                  \n",
      "    2      0.426192   0.451034                                  \n",
      "    3      0.430737   0.44898                                   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.44898])]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_lrs(opt, 1e-4)\n",
    "\n",
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the pytorch source\n",
    "\n",
    "def RNNCell(input, hidden, w_ih, w_hh, b_ih, b_hh):\n",
    "    return F.tanh(F.linear(input, w_ih, b_ih) + F.linear(hidden, w_hh, b_hh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulRnn2(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNNCell(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        outp = []\n",
    "        o = self.h\n",
    "        for c in cs: \n",
    "            o = self.rnn(self.e(c), o)\n",
    "            outp.append(o)\n",
    "        outp = self.l_out(torch.stack(outp))\n",
    "        self.h = repackage_var(o)\n",
    "        return F.log_softmax(outp, dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulRnn2(md.nt, n_fac, 512).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "186292b0ef2245959fdc0ea6af983655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.522839   0.529669  \n",
      "    1      0.490646   0.505466                                  \n",
      "    2      0.476849   0.490029                                  \n",
      "    3      0.471633   0.483625                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.48363])]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.GRU(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the pytorch source code - for reference\n",
    "\n",
    "# def GRUCell(input, hidden, w_ih, w_hh, b_ih, b_hh):\n",
    "#     gi = F.linear(input, w_ih, b_ih)\n",
    "#     gh = F.linear(hidden, w_hh, b_hh)\n",
    "#     i_r, i_i, i_n = gi.chunk(3, 1)\n",
    "#     h_r, h_i, h_n = gh.chunk(3, 1)\n",
    "\n",
    "#     resetgate = F.sigmoid(i_r + h_r)\n",
    "#     inputgate = F.sigmoid(i_i + h_i)\n",
    "#     newgate = F.tanh(i_n + resetgate * h_n)\n",
    "#     return newgate + inputgate * (hidden - newgate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulGRU(md.nt, n_fac, 512).cuda()\n",
    "\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9269aeb9f2f34faab3e7825c6c8c9ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.504086   0.514013  \n",
      "    1      0.468326   0.48185                                   \n",
      "    2      0.449663   0.466684                                  \n",
      "    3      0.440937   0.459561                                  \n",
      "    4      0.434015   0.454837                                  \n",
      "    5      0.42847    0.449195                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.44919])]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 6, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7457b69172246538b9fb8598809ed53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      0.394254   0.431735  \n",
      "    1      0.391121   0.428118                                  \n",
      "    2      0.386359   0.426548                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4265484]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 3, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_next(\"into a b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_next(\"blon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "Now we will try an LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import vocab, data\n",
    "\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "from fastai import sgdr\n",
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_idx = get_cv_idxs(len(xs)-rnn_len-1)\n",
    "# print(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(xs)\n",
    "# print(ys)\n",
    "# md = ColumnarModelData.from_arrays('.', val_idx, xs, ys, bs=512)\n",
    "# print(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_sz, bs, nl):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.nl = vocab_size,nl\n",
    "        self.e = nn.Embedding(vocab_size, embeddings_sz)\n",
    "        self.rnn = nn.LSTM(embeddings_sz, n_hidden, nl, dropout=0.5)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, rnn_len):\n",
    "        bs = rnn_len[0].size(0)\n",
    "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(rnn_len), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.h = (V(torch.zeros(self.nl, bs, n_hidden)),\n",
    "                  V(torch.zeros(self.nl, bs, n_hidden)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulLSTM(len(chars)+1,embeddings_sz, 512, 2).cuda()\n",
    "lo = LayerOptimizer(optim.Adam, m, 1e-2, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{PATH}models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b2c14c9007b48b9a7542ccdae63824b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                 \n",
      "    0      0.594706   0.589509  \n",
      "    1      0.561305   0.559208                                 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.55921])]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 2, lo.opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## He trains for 2^6 epochs... I'm not waiting that long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb7e73ceb51a4361b02eef1c4259f4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                 \n",
      "    0      0.498318   0.495586  \n",
      "    1      0.521561   0.516724                                 \n",
      "    2      0.480379   0.475032                                 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.47503])]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 2**2-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a9db73e78b4b379cfabc4cc7e0aeee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                 \n",
      "    0      0.476808   0.470628  \n",
      "    1      0.470209   0.466648                                 \n",
      "    2      0.465103   0.464341                                 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.46434])]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 2**2-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = TEXT.numericalize(inp)\n",
    "    p = m(VV(idxs.transpose(0,1)))\n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return TEXT.vocab.itos[to_np(r)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "','"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('into a b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "','"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('a ma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "','"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('blon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "into a b, 3, 79, 68, 86, 72, 3, 90, 72, 85, 81, 3, 85, 72, 3, 86, 82, 81, 72, 71, 3, 45, 501, 56, 43, 54, 39, 3, 50, 36, 50, 40, 3, 68, 69, 72, 85, 15, 3, 47, 79, 72, 85, 3, 83, 68, 81, 72, 72, 86, 3, 86, 87, 72, 3, 90, 68, 81, 72, 81, 87, 75, 3, 68, 81, 82, 79, 79,, 8,, 79, 68, 86, 79, 92, 3, 75, 68, 79, 17, 3, 91, 72, 89, 76, 71, 72, 68, 85, 76, 70, 17, 3, 86, 72, 71, 3, 83, 88, 83, 72, 82, 81, 68, 81, \n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('into a b', 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blon    77, 17, 3, 3, 3, 3, 3, 54, 5, 3, 91, 3, 1, 17, 17, 3, 91, 3, 91, 1, 38, 38, ,73, 86, 87,, 87,, 68, 79,, 37, 69, 86, 3, 3, 37, 4, 4, 3, 91, 3, 3, 1, 1, 35, 17, 3, 91, 1, 5, 5, 3, 60, 80, 76, 71, 1, 5, 3, 3, 93, 43, 5, 53, 36, 36, 50, 49, 3, 40, 3, 44, 49, 3, 51, 49, 49, 3, 3, 1, 15, 1, 17, 17, 17, 60, 5, 3, 50, 55, 3, 3, 58, 3, 3, 37, 44, 44, 5, 1, 5, 58, 4, 1, 36, 43, 50, 5, 124, 5, 1, 16, 37,\n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('blon', 400))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
